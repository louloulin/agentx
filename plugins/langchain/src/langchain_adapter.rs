//! LangChainæ¡†æ¶é€‚é…å™¨
//! 
//! æä¾›LangChainæ¡†æ¶ä¸A2Aåè®®çš„é€‚é…åŠŸèƒ½

use crate::python_bridge::PythonBridge;
use crate::error::{LangChainError, LangChainResult};
use agentx_grpc::proto::*;
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::{mpsc, RwLock};
use tracing::{info, debug, error, warn};
use serde_json::{json, Value};

/// LangChainé€‚é…å™¨
pub struct LangChainAdapter {
    /// Pythonæ¡¥æ¥å™¨
    python_bridge: Arc<PythonBridge>,
    /// Agentå®ä¾‹ç¼“å­˜
    agents: Arc<RwLock<HashMap<String, LangChainAgent>>>,
    /// ä¼šè¯ç®¡ç†å™¨
    sessions: Arc<RwLock<HashMap<String, ConversationSession>>>,
}

/// LangChain Agentå®ä¾‹
#[derive(Debug, Clone)]
pub struct LangChainAgent {
    pub id: String,
    pub name: String,
    pub agent_type: String,
    pub model_name: String,
    pub tools: Vec<String>,
    pub memory_type: Option<String>,
    pub config: HashMap<String, Value>,
    pub created_at: chrono::DateTime<chrono::Utc>,
}

/// å¯¹è¯ä¼šè¯
#[derive(Debug, Clone)]
pub struct ConversationSession {
    pub session_id: String,
    pub agent_id: String,
    pub messages: Vec<SessionMessage>,
    pub context: HashMap<String, Value>,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub updated_at: chrono::DateTime<chrono::Utc>,
}

/// ä¼šè¯æ¶ˆæ¯
#[derive(Debug, Clone)]
pub struct SessionMessage {
    pub role: String,
    pub content: String,
    pub timestamp: chrono::DateTime<chrono::Utc>,
    pub metadata: HashMap<String, Value>,
}

impl LangChainAdapter {
    /// åˆ›å»ºæ–°çš„LangChainé€‚é…å™¨
    pub async fn new(python_bridge: Arc<PythonBridge>) -> LangChainResult<Self> {
        info!("ğŸ”§ åˆå§‹åŒ–LangChainé€‚é…å™¨");
        
        Ok(Self {
            python_bridge,
            agents: Arc::new(RwLock::new(HashMap::new())),
            sessions: Arc::new(RwLock::new(HashMap::new())),
        })
    }
    
    /// åˆå§‹åŒ–é€‚é…å™¨
    pub async fn initialize(&self) -> LangChainResult<()> {
        info!("ğŸš€ åˆå§‹åŒ–LangChainé€‚é…å™¨...");
        
        // åˆå§‹åŒ–Pythonç¯å¢ƒ
        self.python_bridge.initialize_langchain_environment().await?;
        
        // é¢„åŠ è½½å¸¸ç”¨æ¨¡å‹å’Œå·¥å…·
        self.preload_common_components().await?;
        
        info!("âœ… LangChainé€‚é…å™¨åˆå§‹åŒ–å®Œæˆ");
        Ok(())
    }
    
    /// å…³é—­é€‚é…å™¨
    pub async fn shutdown(&self) -> LangChainResult<()> {
        info!("ğŸ›‘ å…³é—­LangChainé€‚é…å™¨...");
        
        // æ¸…ç†æ‰€æœ‰ä¼šè¯
        {
            let mut sessions = self.sessions.write().await;
            sessions.clear();
        }
        
        // æ¸…ç†æ‰€æœ‰Agent
        {
            let mut agents = self.agents.write().await;
            agents.clear();
        }
        
        info!("âœ… LangChainé€‚é…å™¨å·²å…³é—­");
        Ok(())
    }
    
    /// å¤„ç†A2Aæ¶ˆæ¯
    pub async fn process_message(&self, request: A2aMessageRequest) -> LangChainResult<A2aMessageRequest> {
        debug!("ğŸ“¨ å¤„ç†A2Aæ¶ˆæ¯: {}", request.message_id);
        
        // è§£ææ¶ˆæ¯ç±»å‹å’Œå†…å®¹
        let message_type = MessageType::from_i32(request.message_type).unwrap_or(MessageType::MessageTypeUnspecified);
        
        match message_type {
            MessageType::MessageTypeRequest => {
                self.handle_request_message(request).await
            }
            MessageType::MessageTypeEvent => {
                self.handle_event_message(request).await
            }
            MessageType::MessageTypeStream => {
                self.handle_stream_message(request).await
            }
            _ => {
                warn!("ä¸æ”¯æŒçš„æ¶ˆæ¯ç±»å‹: {:?}", message_type);
                Err(LangChainError::UnsupportedMessageType(format!("{:?}", message_type)))
            }
        }
    }
    
    /// å¤„ç†è¯·æ±‚æ¶ˆæ¯
    async fn handle_request_message(&self, request: A2aMessageRequest) -> LangChainResult<A2aMessageRequest> {
        debug!("ğŸ”„ å¤„ç†è¯·æ±‚æ¶ˆæ¯");
        
        // æå–æ¶ˆæ¯å†…å®¹
        let payload = request.payload.as_ref()
            .ok_or_else(|| LangChainError::InvalidMessage("ç¼ºå°‘æ¶ˆæ¯è½½è·".to_string()))?;
        
        // è§£æä¸ºJSON
        let content: Value = serde_json::from_slice(&payload.value)
            .map_err(|e| LangChainError::InvalidMessage(format!("JSONè§£æå¤±è´¥: {}", e)))?;
        
        // ç¡®å®šç›®æ ‡Agent
        let agent_id = request.to_agent.clone();
        let agent = self.get_agent(&agent_id).await?;
        
        // è·å–æˆ–åˆ›å»ºä¼šè¯
        let session_id = request.metadata.get("session_id")
            .cloned()
            .unwrap_or_else(|| uuid::Uuid::new_v4().to_string());
        
        let mut session = self.get_or_create_session(&session_id, &agent_id).await?;
        
        // å¤„ç†ä¸åŒç±»å‹çš„è¯·æ±‚
        let response_content = match content.get("type").and_then(|t| t.as_str()) {
            Some("chat") => {
                let user_message = content.get("message")
                    .and_then(|m| m.as_str())
                    .ok_or_else(|| LangChainError::InvalidMessage("ç¼ºå°‘èŠå¤©æ¶ˆæ¯".to_string()))?;
                
                self.handle_chat_request(&agent, &mut session, user_message).await?
            }
            Some("tool_call") => {
                let tool_name = content.get("tool_name")
                    .and_then(|t| t.as_str())
                    .ok_or_else(|| LangChainError::InvalidMessage("ç¼ºå°‘å·¥å…·åç§°".to_string()))?;
                
                let tool_args = content.get("arguments")
                    .cloned()
                    .unwrap_or(json!({}));
                
                self.handle_tool_call(&agent, tool_name, &tool_args).await?
            }
            Some("chain_execution") => {
                let chain_config = content.get("chain")
                    .ok_or_else(|| LangChainError::InvalidMessage("ç¼ºå°‘é“¾é…ç½®".to_string()))?;
                
                self.handle_chain_execution(&agent, chain_config).await?
            }
            _ => {
                return Err(LangChainError::UnsupportedOperation(
                    "ä¸æ”¯æŒçš„è¯·æ±‚ç±»å‹".to_string()
                ));
            }
        };
        
        // æ›´æ–°ä¼šè¯
        self.update_session(session).await?;
        
        // æ„å»ºå“åº”æ¶ˆæ¯
        let response_payload = json!({
            "type": "response",
            "content": response_content,
            "agent_id": agent_id,
            "session_id": session_id,
            "timestamp": chrono::Utc::now().to_rfc3339()
        });
        
        Ok(A2aMessageRequest {
            message_id: uuid::Uuid::new_v4().to_string(),
            from_agent: agent_id,
            to_agent: request.from_agent,
            message_type: MessageType::MessageTypeResponse as i32,
            payload: Some(prost_types::Any {
                type_url: "type.googleapis.com/agentx.a2a.TextPayload".to_string(),
                value: serde_json::to_vec(&response_payload)
                    .map_err(|e| LangChainError::SerializationError(e.to_string()))?,
            }),
            metadata: HashMap::new(),
            timestamp: Some(prost_types::Timestamp::from(std::time::SystemTime::now())),
            ttl_seconds: 300,
        })
    }
    
    /// å¤„ç†èŠå¤©è¯·æ±‚
    async fn handle_chat_request(
        &self,
        agent: &LangChainAgent,
        session: &mut ConversationSession,
        user_message: &str,
    ) -> LangChainResult<Value> {
        debug!("ğŸ’¬ å¤„ç†èŠå¤©è¯·æ±‚: {}", user_message);
        
        // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ä¼šè¯
        session.messages.push(SessionMessage {
            role: "user".to_string(),
            content: user_message.to_string(),
            timestamp: chrono::Utc::now(),
            metadata: HashMap::new(),
        });
        
        // æ„å»ºèŠå¤©è¯·æ±‚
        let chat_request = json!({
            "agent_type": agent.agent_type,
            "model": agent.model_name,
            "messages": session.messages.iter().map(|m| json!({
                "role": m.role,
                "content": m.content
            })).collect::<Vec<_>>(),
            "tools": agent.tools,
            "memory_type": agent.memory_type,
            "config": agent.config
        });
        
        // è°ƒç”¨Python LangChain
        let response = self.python_bridge.call_langchain_chat(chat_request).await?;
        
        // è§£æå“åº”
        let assistant_message = response.get("content")
            .and_then(|c| c.as_str())
            .ok_or_else(|| LangChainError::InvalidResponse("ç¼ºå°‘å“åº”å†…å®¹".to_string()))?;
        
        // æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°ä¼šè¯
        session.messages.push(SessionMessage {
            role: "assistant".to_string(),
            content: assistant_message.to_string(),
            timestamp: chrono::Utc::now(),
            metadata: HashMap::new(),
        });
        
        session.updated_at = chrono::Utc::now();
        
        Ok(json!({
            "message": assistant_message,
            "usage": response.get("usage"),
            "model": agent.model_name
        }))
    }
    
    /// å¤„ç†å·¥å…·è°ƒç”¨
    async fn handle_tool_call(
        &self,
        agent: &LangChainAgent,
        tool_name: &str,
        tool_args: &Value,
    ) -> LangChainResult<Value> {
        debug!("ğŸ”§ å¤„ç†å·¥å…·è°ƒç”¨: {}", tool_name);
        
        // éªŒè¯å·¥å…·æ˜¯å¦å¯ç”¨
        if !agent.tools.contains(&tool_name.to_string()) {
            return Err(LangChainError::ToolNotFound(tool_name.to_string()));
        }
        
        // æ„å»ºå·¥å…·è°ƒç”¨è¯·æ±‚
        let tool_request = json!({
            "tool_name": tool_name,
            "arguments": tool_args,
            "agent_config": agent.config
        });
        
        // è°ƒç”¨Python LangChainå·¥å…·
        let response = self.python_bridge.call_langchain_tool(tool_request).await?;
        
        Ok(response)
    }
    
    /// å¤„ç†é“¾æ‰§è¡Œ
    async fn handle_chain_execution(
        &self,
        agent: &LangChainAgent,
        chain_config: &Value,
    ) -> LangChainResult<Value> {
        debug!("â›“ï¸ å¤„ç†é“¾æ‰§è¡Œ");
        
        // æ„å»ºé“¾æ‰§è¡Œè¯·æ±‚
        let chain_request = json!({
            "chain_config": chain_config,
            "agent_config": agent.config,
            "model": agent.model_name
        });
        
        // è°ƒç”¨Python LangChainé“¾
        let response = self.python_bridge.call_langchain_chain(chain_request).await?;
        
        Ok(response)
    }
    
    /// å¤„ç†äº‹ä»¶æ¶ˆæ¯
    async fn handle_event_message(&self, request: A2aMessageRequest) -> LangChainResult<A2aMessageRequest> {
        debug!("ğŸ“¢ å¤„ç†äº‹ä»¶æ¶ˆæ¯");
        
        // TODO: å®ç°äº‹ä»¶æ¶ˆæ¯å¤„ç†
        Ok(request)
    }
    
    /// å¤„ç†æµå¼æ¶ˆæ¯
    async fn handle_stream_message(&self, request: A2aMessageRequest) -> LangChainResult<A2aMessageRequest> {
        debug!("ğŸŒŠ å¤„ç†æµå¼æ¶ˆæ¯");
        
        // TODO: å®ç°æµå¼æ¶ˆæ¯å¤„ç†
        Ok(request)
    }
    
    /// å¤„ç†æµå¼æ•°æ®
    pub async fn process_stream(
        &self,
        mut stream: tonic::Streaming<A2aStreamChunk>,
        tx: mpsc::Sender<Result<A2aStreamChunk, tonic::Status>>,
    ) -> LangChainResult<()> {
        info!("ğŸŒŠ å¼€å§‹å¤„ç†æµå¼æ•°æ®");
        
        while let Some(chunk) = stream.message().await.map_err(|e| {
            LangChainError::StreamError(format!("æµè¯»å–é”™è¯¯: {}", e))
        })? {
            debug!("ğŸ“¦ å¤„ç†æµå—: {}", chunk.stream_id);
            
            // å¤„ç†æµå—
            let processed_chunk = self.process_stream_chunk(chunk).await?;
            
            // å‘é€å¤„ç†åçš„å—
            if tx.send(Ok(processed_chunk)).await.is_err() {
                warn!("æµæ¥æ”¶å™¨å·²å…³é—­");
                break;
            }
        }
        
        info!("âœ… æµå¼æ•°æ®å¤„ç†å®Œæˆ");
        Ok(())
    }
    
    /// å¤„ç†å•ä¸ªæµå—
    async fn process_stream_chunk(&self, chunk: A2aStreamChunk) -> LangChainResult<A2aStreamChunk> {
        // TODO: å®ç°æµå—å¤„ç†é€»è¾‘
        Ok(chunk)
    }
    
    /// æ³¨å†ŒAgent
    pub async fn register_agent(
        &self,
        agent_info: AgentInfo,
        capabilities: Vec<Capability>,
    ) -> LangChainResult<String> {
        info!("ğŸ“ æ³¨å†ŒLangChain Agent: {}", agent_info.name);
        
        // åˆ›å»ºLangChain Agentå®ä¾‹
        let agent = LangChainAgent {
            id: agent_info.id.clone(),
            name: agent_info.name.clone(),
            agent_type: agent_info.metadata.get("agent_type")
                .cloned()
                .unwrap_or_else(|| "conversational".to_string()),
            model_name: agent_info.metadata.get("model")
                .cloned()
                .unwrap_or_else(|| "gpt-3.5-turbo".to_string()),
            tools: capabilities.iter()
                .filter(|c| c.r#type == CapabilityType::CapabilityTypeTool as i32)
                .map(|c| c.name.clone())
                .collect(),
            memory_type: agent_info.metadata.get("memory_type").cloned(),
            config: agent_info.metadata.iter()
                .map(|(k, v)| (k.clone(), json!(v)))
                .collect(),
            created_at: chrono::Utc::now(),
        };
        
        // åœ¨Pythonç¯å¢ƒä¸­åˆ›å»ºAgent
        let create_request = json!({
            "agent_id": agent.id,
            "agent_type": agent.agent_type,
            "model": agent.model_name,
            "tools": agent.tools,
            "memory_type": agent.memory_type,
            "config": agent.config
        });
        
        self.python_bridge.create_langchain_agent(create_request).await?;
        
        // ç¼“å­˜Agent
        {
            let mut agents = self.agents.write().await;
            agents.insert(agent.id.clone(), agent);
        }
        
        info!("âœ… LangChain Agentæ³¨å†ŒæˆåŠŸ: {}", agent_info.id);
        Ok(agent_info.id)
    }
    
    /// æ³¨é”€Agent
    pub async fn unregister_agent(&self, agent_id: &str) -> LangChainResult<()> {
        info!("ğŸ—‘ï¸ æ³¨é”€LangChain Agent: {}", agent_id);
        
        // ä»ç¼“å­˜ä¸­ç§»é™¤
        {
            let mut agents = self.agents.write().await;
            agents.remove(agent_id);
        }
        
        // æ¸…ç†ç›¸å…³ä¼šè¯
        {
            let mut sessions = self.sessions.write().await;
            sessions.retain(|_, session| session.agent_id != agent_id);
        }
        
        // åœ¨Pythonç¯å¢ƒä¸­åˆ é™¤Agent
        self.python_bridge.delete_langchain_agent(agent_id).await?;
        
        info!("âœ… LangChain Agentæ³¨é”€å®Œæˆ: {}", agent_id);
        Ok(())
    }
    
    /// è·å–Agentèƒ½åŠ›
    pub async fn get_agent_capabilities(&self, agent_id: &str) -> LangChainResult<Vec<Capability>> {
        let agent = self.get_agent(agent_id).await?;
        
        let mut capabilities = vec![
            Capability {
                id: "chat".to_string(),
                name: "èŠå¤©å¯¹è¯".to_string(),
                description: "ä¸ç”¨æˆ·è¿›è¡Œè‡ªç„¶è¯­è¨€å¯¹è¯".to_string(),
                r#type: CapabilityType::CapabilityTypeSkill as i32,
                parameters: vec![],
                returns: vec![],
                metadata: HashMap::new(),
            }
        ];
        
        // æ·»åŠ å·¥å…·èƒ½åŠ›
        for tool in &agent.tools {
            capabilities.push(Capability {
                id: tool.clone(),
                name: tool.clone(),
                description: format!("LangChainå·¥å…·: {}", tool),
                r#type: CapabilityType::CapabilityTypeTool as i32,
                parameters: vec![],
                returns: vec![],
                metadata: HashMap::new(),
            });
        }
        
        Ok(capabilities)
    }
    
    /// è·å–Agent
    async fn get_agent(&self, agent_id: &str) -> LangChainResult<LangChainAgent> {
        let agents = self.agents.read().await;
        agents.get(agent_id)
            .cloned()
            .ok_or_else(|| LangChainError::AgentNotFound(agent_id.to_string()))
    }
    
    /// è·å–æˆ–åˆ›å»ºä¼šè¯
    async fn get_or_create_session(
        &self,
        session_id: &str,
        agent_id: &str,
    ) -> LangChainResult<ConversationSession> {
        let sessions = self.sessions.read().await;
        
        if let Some(session) = sessions.get(session_id) {
            Ok(session.clone())
        } else {
            drop(sessions);
            
            let session = ConversationSession {
                session_id: session_id.to_string(),
                agent_id: agent_id.to_string(),
                messages: Vec::new(),
                context: HashMap::new(),
                created_at: chrono::Utc::now(),
                updated_at: chrono::Utc::now(),
            };
            
            let mut sessions = self.sessions.write().await;
            sessions.insert(session_id.to_string(), session.clone());
            
            Ok(session)
        }
    }
    
    /// æ›´æ–°ä¼šè¯
    async fn update_session(&self, session: ConversationSession) -> LangChainResult<()> {
        let mut sessions = self.sessions.write().await;
        sessions.insert(session.session_id.clone(), session);
        Ok(())
    }
    
    /// é¢„åŠ è½½å¸¸ç”¨ç»„ä»¶
    async fn preload_common_components(&self) -> LangChainResult<()> {
        info!("ğŸ“¦ é¢„åŠ è½½LangChainå¸¸ç”¨ç»„ä»¶...");
        
        // é¢„åŠ è½½å¸¸ç”¨æ¨¡å‹
        let models = vec!["gpt-3.5-turbo", "gpt-4", "claude-3-sonnet"];
        for model in models {
            if let Err(e) = self.python_bridge.preload_model(model).await {
                warn!("é¢„åŠ è½½æ¨¡å‹ {} å¤±è´¥: {}", model, e);
            }
        }
        
        // é¢„åŠ è½½å¸¸ç”¨å·¥å…·
        let tools = vec!["search", "calculator", "weather", "web_scraper"];
        for tool in tools {
            if let Err(e) = self.python_bridge.preload_tool(tool).await {
                warn!("é¢„åŠ è½½å·¥å…· {} å¤±è´¥: {}", tool, e);
            }
        }
        
        info!("âœ… å¸¸ç”¨ç»„ä»¶é¢„åŠ è½½å®Œæˆ");
        Ok(())
    }
}
