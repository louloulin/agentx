//! åŸºäºçœŸå®ç½‘ç»œçš„æ€§èƒ½åŸºå‡†æµ‹è¯•
//! 
//! æä¾›åœ¨çœŸå®ç½‘ç»œç¯å¢ƒä¸­çš„æ€§èƒ½æµ‹è¯•ï¼ŒåŒ…æ‹¬ï¼š
//! - è·¨ç½‘ç»œçš„æ¶ˆæ¯è·¯ç”±å»¶è¿Ÿæµ‹è¯•
//! - åˆ†å¸ƒå¼Agenté€šä¿¡æ€§èƒ½æµ‹è¯•
//! - ç½‘ç»œæŠ–åŠ¨å’Œä¸¢åŒ…æƒ…å†µä¸‹çš„æ€§èƒ½æµ‹è¯•
//! - çœŸå®è´Ÿè½½ä¸‹çš„ç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•

use agentx_a2a::{A2AResult, A2AError, A2AMessage, MessageRole, AgentCard};
use agentx_cluster::{ClusterManager, ClusterConfig};
use agentx_router::{MessageRouter, RouterConfig};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::net::{SocketAddr, IpAddr, Ipv4Addr};
use std::sync::Arc;
use std::time::{Duration, Instant, SystemTime};
use tokio::sync::{RwLock, Semaphore};
use tokio::time::timeout;
use tracing::{info, debug};

/// çœŸå®ç½‘ç»œåŸºå‡†æµ‹è¯•ç®¡ç†å™¨
pub struct RealNetworkBenchmarks {
    /// æµ‹è¯•é…ç½®
    config: RealNetworkConfig,
    /// é›†ç¾¤ç®¡ç†å™¨
    #[allow(dead_code)]
    cluster_manager: Arc<ClusterManager>,
    /// æ¶ˆæ¯è·¯ç”±å™¨ï¼ˆå¯é€‰ï¼Œç”¨äºåŸºå‡†æµ‹è¯•ï¼‰
    router: Arc<RwLock<Option<MessageRouter>>>,
    /// æµ‹è¯•èŠ‚ç‚¹åˆ—è¡¨
    test_nodes: Vec<TestNode>,
    /// ç½‘ç»œæ¨¡æ‹Ÿå™¨
    network_simulator: NetworkSimulator,
}

/// çœŸå®ç½‘ç»œæµ‹è¯•é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RealNetworkConfig {
    /// æµ‹è¯•èŠ‚ç‚¹æ•°é‡
    pub node_count: usize,
    /// æ¯ä¸ªèŠ‚ç‚¹çš„Agentæ•°é‡
    pub agents_per_node: usize,
    /// æµ‹è¯•æŒç»­æ—¶é—´
    pub test_duration: Duration,
    /// æ¶ˆæ¯å‘é€é¢‘ç‡ï¼ˆæ¶ˆæ¯/ç§’ï¼‰
    pub message_rate: f64,
    /// ç½‘ç»œå»¶è¿Ÿæ¨¡æ‹Ÿï¼ˆæ¯«ç§’ï¼‰
    pub simulated_latency_ms: u64,
    /// ä¸¢åŒ…ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
    pub packet_loss_rate: f64,
    /// ç½‘ç»œæŠ–åŠ¨ï¼ˆæ¯«ç§’ï¼‰
    pub jitter_ms: u64,
    /// å¸¦å®½é™åˆ¶ï¼ˆMbpsï¼‰
    pub bandwidth_limit_mbps: Option<f64>,
    /// æ˜¯å¦å¯ç”¨ç½‘ç»œåˆ†åŒºæµ‹è¯•
    pub enable_network_partition: bool,
}

impl Default for RealNetworkConfig {
    fn default() -> Self {
        Self {
            node_count: 5,
            agents_per_node: 10,
            test_duration: Duration::from_secs(300), // 5åˆ†é’Ÿ
            message_rate: 100.0, // 100 msg/s
            simulated_latency_ms: 50, // 50mså»¶è¿Ÿ
            packet_loss_rate: 0.1, // 0.1%ä¸¢åŒ…ç‡
            jitter_ms: 10, // 10msæŠ–åŠ¨
            bandwidth_limit_mbps: Some(100.0), // 100Mbps
            enable_network_partition: false,
        }
    }
}

/// æµ‹è¯•èŠ‚ç‚¹
#[derive(Debug, Clone)]
pub struct TestNode {
    /// èŠ‚ç‚¹ID
    pub node_id: String,
    /// èŠ‚ç‚¹åœ°å€
    pub address: SocketAddr,
    /// èŠ‚ç‚¹ä¸Šçš„Agentåˆ—è¡¨
    pub agents: Vec<String>,
    /// èŠ‚ç‚¹çŠ¶æ€
    pub status: NodeStatus,
    /// æ€§èƒ½æŒ‡æ ‡
    pub metrics: NodeMetrics,
}

/// èŠ‚ç‚¹çŠ¶æ€
#[derive(Debug, Clone, PartialEq)]
pub enum NodeStatus {
    /// åœ¨çº¿
    Online,
    /// ç¦»çº¿
    Offline,
    /// ç½‘ç»œåˆ†åŒº
    Partitioned,
    /// æ•…éšœ
    Failed(String),
}

/// èŠ‚ç‚¹æ€§èƒ½æŒ‡æ ‡
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct NodeMetrics {
    /// æ¶ˆæ¯å‘é€æ•°é‡
    pub messages_sent: u64,
    /// æ¶ˆæ¯æ¥æ”¶æ•°é‡
    pub messages_received: u64,
    /// å¹³å‡å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
    pub avg_latency_ms: f64,
    /// é”™è¯¯æ•°é‡
    pub error_count: u64,
    /// CPUä½¿ç”¨ç‡
    pub cpu_usage: f64,
    /// å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰
    pub memory_usage_mb: f64,
    /// ç½‘ç»œå¸¦å®½ä½¿ç”¨ï¼ˆMbpsï¼‰
    pub bandwidth_usage_mbps: f64,
}

/// ç½‘ç»œæ¨¡æ‹Ÿå™¨
pub struct NetworkSimulator {
    /// å»¶è¿Ÿé…ç½®
    latency_ms: u64,
    /// ä¸¢åŒ…ç‡
    packet_loss_rate: f64,
    /// æŠ–åŠ¨
    jitter_ms: u64,
    /// å¸¦å®½é™åˆ¶
    bandwidth_limit: Option<f64>,
}

/// çœŸå®ç½‘ç»œæµ‹è¯•ç»“æœ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RealNetworkBenchmarkResult {
    /// æµ‹è¯•åç§°
    pub test_name: String,
    /// æµ‹è¯•å¼€å§‹æ—¶é—´
    pub start_time: SystemTime,
    /// æµ‹è¯•æŒç»­æ—¶é—´
    pub duration: Duration,
    /// æ€»æ¶ˆæ¯æ•°é‡
    pub total_messages: u64,
    /// æˆåŠŸæ¶ˆæ¯æ•°é‡
    pub successful_messages: u64,
    /// å¤±è´¥æ¶ˆæ¯æ•°é‡
    pub failed_messages: u64,
    /// å¹³å‡ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
    pub avg_e2e_latency_ms: f64,
    /// P95å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
    pub p95_latency_ms: f64,
    /// P99å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
    pub p99_latency_ms: f64,
    /// æœ€å¤§å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
    pub max_latency_ms: f64,
    /// ååé‡ï¼ˆæ¶ˆæ¯/ç§’ï¼‰
    pub throughput_msg_per_sec: f64,
    /// é”™è¯¯ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
    pub error_rate_percent: f64,
    /// ç½‘ç»œåˆ©ç”¨ç‡
    pub network_utilization: NetworkUtilization,
    /// èŠ‚ç‚¹æ€§èƒ½æŒ‡æ ‡
    pub node_metrics: HashMap<String, NodeMetrics>,
    /// æµ‹è¯•æ˜¯å¦é€šè¿‡
    pub passed: bool,
    /// å¤±è´¥åŸå› 
    pub failure_reason: Option<String>,
}

/// ç½‘ç»œåˆ©ç”¨ç‡
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NetworkUtilization {
    /// å¹³å‡å¸¦å®½ä½¿ç”¨ï¼ˆMbpsï¼‰
    pub avg_bandwidth_mbps: f64,
    /// å³°å€¼å¸¦å®½ä½¿ç”¨ï¼ˆMbpsï¼‰
    pub peak_bandwidth_mbps: f64,
    /// ç½‘ç»œå»¶è¿Ÿåˆ†å¸ƒ
    pub latency_distribution: LatencyDistribution,
    /// ä¸¢åŒ…ç»Ÿè®¡
    pub packet_loss_stats: PacketLossStats,
}

/// å»¶è¿Ÿåˆ†å¸ƒ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LatencyDistribution {
    /// æœ€å°å»¶è¿Ÿ
    pub min_ms: f64,
    /// æœ€å¤§å»¶è¿Ÿ
    pub max_ms: f64,
    /// å¹³å‡å»¶è¿Ÿ
    pub avg_ms: f64,
    /// æ ‡å‡†å·®
    pub std_dev_ms: f64,
    /// ç™¾åˆ†ä½æ•°
    pub percentiles: HashMap<String, f64>, // P50, P90, P95, P99
}

/// ä¸¢åŒ…ç»Ÿè®¡
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PacketLossStats {
    /// æ€»å‘é€åŒ…æ•°
    pub total_packets: u64,
    /// ä¸¢å¤±åŒ…æ•°
    pub lost_packets: u64,
    /// ä¸¢åŒ…ç‡
    pub loss_rate_percent: f64,
    /// é‡ä¼ æ¬¡æ•°
    pub retransmissions: u64,
}

impl RealNetworkBenchmarks {
    /// åˆ›å»ºæ–°çš„çœŸå®ç½‘ç»œåŸºå‡†æµ‹è¯•ç®¡ç†å™¨
    pub async fn new(config: RealNetworkConfig) -> A2AResult<Self> {
        info!("ğŸŒ åˆ›å»ºçœŸå®ç½‘ç»œåŸºå‡†æµ‹è¯•ç®¡ç†å™¨");
        
        // åˆ›å»ºé›†ç¾¤ç®¡ç†å™¨
        let cluster_config = ClusterConfig::default();
        let cluster_manager = Arc::new(ClusterManager::new(cluster_config).await
            .map_err(|e| A2AError::internal(format!("åˆ›å»ºé›†ç¾¤ç®¡ç†å™¨å¤±è´¥: {}", e)))?);
        
        // åˆ›å»ºæ¶ˆæ¯è·¯ç”±å™¨ï¼ˆç®€åŒ–å®ç°ï¼Œç”¨äºåŸºå‡†æµ‹è¯•ï¼‰
        let _router_config = RouterConfig::default();
        // æ³¨æ„ï¼šåœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œéœ€è¦åˆ›å»ºçœŸå®çš„è·¯ç”±å™¨ä¾èµ–
        // ä¸ºäº†åŸºå‡†æµ‹è¯•ï¼Œæˆ‘ä»¬æš‚æ—¶è·³è¿‡è·¯ç”±å™¨çš„åˆ›å»º
        let router = Arc::new(RwLock::new(None::<MessageRouter>));
        
        // åˆå§‹åŒ–æµ‹è¯•èŠ‚ç‚¹
        let test_nodes = Self::initialize_test_nodes(&config).await?;
        
        // åˆ›å»ºç½‘ç»œæ¨¡æ‹Ÿå™¨
        let network_simulator = NetworkSimulator::new(
            config.simulated_latency_ms,
            config.packet_loss_rate,
            config.jitter_ms,
            config.bandwidth_limit_mbps,
        );
        
        Ok(Self {
            config,
            cluster_manager,
            router,
            test_nodes,
            network_simulator,
        })
    }
    
    /// è¿è¡Œå®Œæ•´çš„çœŸå®ç½‘ç»œåŸºå‡†æµ‹è¯•å¥—ä»¶
    pub async fn run_full_benchmark_suite(&mut self) -> A2AResult<Vec<RealNetworkBenchmarkResult>> {
        info!("ğŸš€ å¼€å§‹çœŸå®ç½‘ç»œåŸºå‡†æµ‹è¯•å¥—ä»¶");
        
        let mut results = Vec::new();
        
        // 1. åŸºç¡€ç½‘ç»œå»¶è¿Ÿæµ‹è¯•
        info!("ğŸ“¡ æ‰§è¡ŒåŸºç¡€ç½‘ç»œå»¶è¿Ÿæµ‹è¯•");
        let latency_result = self.benchmark_network_latency().await?;
        results.push(latency_result);
        
        // 2. é«˜å¹¶å‘æ¶ˆæ¯è·¯ç”±æµ‹è¯•
        info!("ğŸ”€ æ‰§è¡Œé«˜å¹¶å‘æ¶ˆæ¯è·¯ç”±æµ‹è¯•");
        let routing_result = self.benchmark_concurrent_routing().await?;
        results.push(routing_result);
        
        // 3. åˆ†å¸ƒå¼Agenté€šä¿¡æµ‹è¯•
        info!("ğŸ‘¥ æ‰§è¡Œåˆ†å¸ƒå¼Agenté€šä¿¡æµ‹è¯•");
        let agent_comm_result = self.benchmark_distributed_agents().await?;
        results.push(agent_comm_result);
        
        // 4. ç½‘ç»œæ•…éšœæ¢å¤æµ‹è¯•
        if self.config.enable_network_partition {
            info!("ğŸ”§ æ‰§è¡Œç½‘ç»œæ•…éšœæ¢å¤æµ‹è¯•");
            let recovery_result = self.benchmark_network_recovery().await?;
            results.push(recovery_result);
        }
        
        // 5. é•¿æœŸç¨³å®šæ€§æµ‹è¯•
        info!("â±ï¸ æ‰§è¡Œé•¿æœŸç¨³å®šæ€§æµ‹è¯•");
        let stability_result = self.benchmark_long_term_stability().await?;
        results.push(stability_result);
        
        info!("âœ… çœŸå®ç½‘ç»œåŸºå‡†æµ‹è¯•å¥—ä»¶å®Œæˆ");
        Ok(results)
    }

    /// åŸºç¡€ç½‘ç»œå»¶è¿ŸåŸºå‡†æµ‹è¯•
    async fn benchmark_network_latency(&mut self) -> A2AResult<RealNetworkBenchmarkResult> {
        let test_name = "network_latency".to_string();
        let start_time = SystemTime::now();
        let mut latencies = Vec::new();
        let mut successful_messages = 0;
        let mut failed_messages = 0;

        info!("å¼€å§‹ç½‘ç»œå»¶è¿ŸåŸºå‡†æµ‹è¯•");

        // åˆ›å»ºæµ‹è¯•æ¶ˆæ¯
        let test_message_count = 1000;
        let semaphore = Arc::new(Semaphore::new(50)); // é™åˆ¶å¹¶å‘æ•°

        let mut handles = Vec::new();

        for i in 0..test_message_count {
            let permit = semaphore.clone().acquire_owned().await.unwrap();
            let nodes = self.test_nodes.clone();
            let simulator = self.network_simulator.clone();

            let handle = tokio::spawn(async move {
                let _permit = permit; // ä¿æŒpermitç›´åˆ°ä»»åŠ¡å®Œæˆ

                // é€‰æ‹©æºèŠ‚ç‚¹å’Œç›®æ ‡èŠ‚ç‚¹
                let source_node = &nodes[i % nodes.len()];
                let target_node = &nodes[(i + 1) % nodes.len()];

                let message = A2AMessage::new_text(
                    MessageRole::Agent,
                    format!("å»¶è¿Ÿæµ‹è¯•æ¶ˆæ¯ {}", i),
                );

                let start = Instant::now();

                // æ¨¡æ‹Ÿç½‘ç»œä¼ è¾“
                let result = simulator.simulate_message_transmission(&message,
                    &source_node.address, &target_node.address).await;

                let latency = start.elapsed();

                match result {
                    Ok(_) => (latency.as_secs_f64() * 1000.0, true), // è½¬æ¢ä¸ºæ¯«ç§’
                    Err(_) => (0.0, false),
                }
            });

            handles.push(handle);
        }

        // æ”¶é›†ç»“æœ
        for handle in handles {
            match handle.await {
                Ok((latency, success)) => {
                    if success {
                        latencies.push(latency);
                        successful_messages += 1;
                    } else {
                        failed_messages += 1;
                    }
                }
                Err(_) => failed_messages += 1,
            }
        }

        let duration = start_time.elapsed().unwrap();

        // è®¡ç®—ç»Ÿè®¡æ•°æ®
        let (avg_latency, p95_latency, p99_latency, max_latency) =
            Self::calculate_latency_stats(&latencies);

        let total_messages = successful_messages + failed_messages;
        let throughput = successful_messages as f64 / duration.as_secs_f64();
        let error_rate = (failed_messages as f64 / total_messages as f64) * 100.0;

        // æ£€æŸ¥æ˜¯å¦é€šè¿‡æµ‹è¯•ï¼ˆå»¶è¿Ÿ < 10msï¼Œé”™è¯¯ç‡ < 1%ï¼‰
        let passed = avg_latency < 10.0 && error_rate < 1.0;
        let failure_reason = if !passed {
            Some(format!("å¹³å‡å»¶è¿Ÿ {:.2}ms æˆ–é”™è¯¯ç‡ {:.2}% è¶…è¿‡é˜ˆå€¼", avg_latency, error_rate))
        } else {
            None
        };

        info!("ç½‘ç»œå»¶è¿Ÿæµ‹è¯•å®Œæˆ: å¹³å‡å»¶è¿Ÿ {:.2}ms, ååé‡ {:.0} msg/s, é”™è¯¯ç‡ {:.2}%",
              avg_latency, throughput, error_rate);

        Ok(RealNetworkBenchmarkResult {
            test_name,
            start_time,
            duration,
            total_messages,
            successful_messages,
            failed_messages,
            avg_e2e_latency_ms: avg_latency,
            p95_latency_ms: p95_latency,
            p99_latency_ms: p99_latency,
            max_latency_ms: max_latency,
            throughput_msg_per_sec: throughput,
            error_rate_percent: error_rate,
            network_utilization: self.calculate_network_utilization(&latencies).await,
            node_metrics: self.collect_node_metrics().await,
            passed,
            failure_reason,
        })
    }

    /// é«˜å¹¶å‘æ¶ˆæ¯è·¯ç”±åŸºå‡†æµ‹è¯•
    async fn benchmark_concurrent_routing(&mut self) -> A2AResult<RealNetworkBenchmarkResult> {
        let test_name = "concurrent_routing".to_string();
        let start_time = SystemTime::now();
        let mut latencies = Vec::new();
        let mut successful_messages = 0;
        let mut failed_messages = 0;

        info!("å¼€å§‹é«˜å¹¶å‘æ¶ˆæ¯è·¯ç”±åŸºå‡†æµ‹è¯•");

        let concurrent_agents = self.config.agents_per_node * self.config.node_count;
        let messages_per_agent = 100;
        let total_messages = concurrent_agents * messages_per_agent;

        let semaphore = Arc::new(Semaphore::new(concurrent_agents));
        let mut handles = Vec::new();

        for agent_id in 0..concurrent_agents {
            let permit = semaphore.clone().acquire_owned().await.unwrap();
            let _router = self.router.clone();
            let _nodes = self.test_nodes.clone();

            let handle = tokio::spawn(async move {
                let _permit = permit;
                let mut agent_latencies = Vec::new();
                let mut agent_successes = 0;
                let mut agent_failures = 0;

                for msg_id in 0..messages_per_agent {
                    let message = A2AMessage::new_text(
                        MessageRole::Agent,
                        format!("Agent {} æ¶ˆæ¯ {}", agent_id, msg_id),
                    );

                    let start = Instant::now();

                    // æ¨¡æ‹Ÿè·¯ç”±å™¨å‘é€æ¶ˆæ¯ï¼ˆç®€åŒ–å®ç°ï¼‰
                    let result = timeout(
                        Duration::from_millis(100), // 100msè¶…æ—¶
                        Self::simulate_router_message_send(message)
                    ).await;

                    let latency = start.elapsed();

                    match result {
                        Ok(Ok(_)) => {
                            agent_latencies.push(latency.as_secs_f64() * 1000.0);
                            agent_successes += 1;
                        }
                        _ => agent_failures += 1,
                    }
                }

                (agent_latencies, agent_successes, agent_failures)
            });

            handles.push(handle);
        }

        // æ”¶é›†æ‰€æœ‰Agentçš„ç»“æœ
        for handle in handles {
            match handle.await {
                Ok((agent_latencies, successes, failures)) => {
                    latencies.extend(agent_latencies);
                    successful_messages += successes;
                    failed_messages += failures;
                }
                Err(_) => failed_messages += messages_per_agent as u64,
            }
        }

        let duration = start_time.elapsed().unwrap();

        // è®¡ç®—ç»Ÿè®¡æ•°æ®
        let (avg_latency, p95_latency, p99_latency, max_latency) =
            Self::calculate_latency_stats(&latencies);

        let throughput = successful_messages as f64 / duration.as_secs_f64();
        let error_rate = (failed_messages as f64 / total_messages as f64) * 100.0;

        // æ£€æŸ¥æ˜¯å¦é€šè¿‡æµ‹è¯•ï¼ˆå»¶è¿Ÿ < 10msï¼Œååé‡ > 1000 msg/sï¼Œé”™è¯¯ç‡ < 1%ï¼‰
        let passed = avg_latency < 10.0 && throughput > 1000.0 && error_rate < 1.0;
        let failure_reason = if !passed {
            Some(format!("æ€§èƒ½æŒ‡æ ‡æœªè¾¾æ ‡: å»¶è¿Ÿ {:.2}ms, ååé‡ {:.0} msg/s, é”™è¯¯ç‡ {:.2}%",
                        avg_latency, throughput, error_rate))
        } else {
            None
        };

        info!("é«˜å¹¶å‘è·¯ç”±æµ‹è¯•å®Œæˆ: å¹³å‡å»¶è¿Ÿ {:.2}ms, ååé‡ {:.0} msg/s, é”™è¯¯ç‡ {:.2}%",
              avg_latency, throughput, error_rate);

        Ok(RealNetworkBenchmarkResult {
            test_name,
            start_time,
            duration,
            total_messages: total_messages as u64,
            successful_messages,
            failed_messages,
            avg_e2e_latency_ms: avg_latency,
            p95_latency_ms: p95_latency,
            p99_latency_ms: p99_latency,
            max_latency_ms: max_latency,
            throughput_msg_per_sec: throughput,
            error_rate_percent: error_rate,
            network_utilization: self.calculate_network_utilization(&latencies).await,
            node_metrics: self.collect_node_metrics().await,
            passed,
            failure_reason,
        })
    }

    /// åˆ†å¸ƒå¼Agenté€šä¿¡åŸºå‡†æµ‹è¯•
    async fn benchmark_distributed_agents(&mut self) -> A2AResult<RealNetworkBenchmarkResult> {
        let test_name = "distributed_agents".to_string();
        let start_time = SystemTime::now();

        info!("å¼€å§‹åˆ†å¸ƒå¼Agenté€šä¿¡åŸºå‡†æµ‹è¯•");

        // åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šåˆ›å»ºAgent
        let mut all_agents = Vec::new();
        for node in &self.test_nodes {
            for i in 0..self.config.agents_per_node {
                let agent_id = format!("agent_{}_{}", node.node_id, i);
                let agent_card = AgentCard::new(
                    agent_id.clone(),
                    format!("æµ‹è¯•Agent {}", agent_id),
                    "åˆ†å¸ƒå¼é€šä¿¡æµ‹è¯•Agent".to_string(),
                    "1.0.0".to_string(),
                );
                all_agents.push((agent_id, agent_card, node.address));
            }
        }

        let mut latencies = Vec::new();
        let mut successful_messages = 0;
        let mut failed_messages = 0;

        // æ‰§è¡ŒAgenté—´é€šä¿¡æµ‹è¯•
        let test_duration = Duration::from_secs(60); // 1åˆ†é’Ÿæµ‹è¯•
        let message_interval = Duration::from_millis(100); // æ¯100mså‘é€ä¸€æ¡æ¶ˆæ¯
        let test_start = Instant::now();

        while test_start.elapsed() < test_duration {
            let mut round_handles = Vec::new();

            // æ¯è½®é€‰æ‹©ä¸€äº›Agentè¿›è¡Œé€šä¿¡
            for i in (0..all_agents.len()).step_by(2) {
                if i + 1 < all_agents.len() {
                    let sender = all_agents[i].clone();
                    let receiver = all_agents[i + 1].clone();

                    let handle = tokio::spawn(async move {
                        let message = A2AMessage::new_text(
                            MessageRole::Agent,
                            format!("ä» {} åˆ° {} çš„æ¶ˆæ¯", sender.0, receiver.0),
                        );

                        let start = Instant::now();

                        // æ¨¡æ‹Ÿè·¨èŠ‚ç‚¹æ¶ˆæ¯ä¼ è¾“
                        let result = Self::simulate_cross_node_communication(
                            &sender.2, &receiver.2, &message
                        ).await;

                        let latency = start.elapsed();

                        match result {
                            Ok(_) => (latency.as_secs_f64() * 1000.0, true),
                            Err(_) => (0.0, false),
                        }
                    });

                    round_handles.push(handle);
                }
            }

            // æ”¶é›†æœ¬è½®ç»“æœ
            for handle in round_handles {
                match handle.await {
                    Ok((latency, success)) => {
                        if success {
                            latencies.push(latency);
                            successful_messages += 1;
                        } else {
                            failed_messages += 1;
                        }
                    }
                    Err(_) => failed_messages += 1,
                }
            }

            tokio::time::sleep(message_interval).await;
        }

        let duration = start_time.elapsed().unwrap();

        // è®¡ç®—ç»Ÿè®¡æ•°æ®
        let (avg_latency, p95_latency, p99_latency, max_latency) =
            Self::calculate_latency_stats(&latencies);

        let total_messages = successful_messages + failed_messages;
        let throughput = successful_messages as f64 / duration.as_secs_f64();
        let error_rate = (failed_messages as f64 / total_messages as f64) * 100.0;

        // æ£€æŸ¥æ˜¯å¦é€šè¿‡æµ‹è¯•
        let passed = avg_latency < 50.0 && error_rate < 2.0; // åˆ†å¸ƒå¼é€šä¿¡å…è®¸æ›´é«˜å»¶è¿Ÿ
        let failure_reason = if !passed {
            Some(format!("åˆ†å¸ƒå¼é€šä¿¡æ€§èƒ½ä¸è¾¾æ ‡: å»¶è¿Ÿ {:.2}ms, é”™è¯¯ç‡ {:.2}%",
                        avg_latency, error_rate))
        } else {
            None
        };

        info!("åˆ†å¸ƒå¼Agenté€šä¿¡æµ‹è¯•å®Œæˆ: å¹³å‡å»¶è¿Ÿ {:.2}ms, ååé‡ {:.0} msg/s, é”™è¯¯ç‡ {:.2}%",
              avg_latency, throughput, error_rate);

        Ok(RealNetworkBenchmarkResult {
            test_name,
            start_time,
            duration,
            total_messages,
            successful_messages,
            failed_messages,
            avg_e2e_latency_ms: avg_latency,
            p95_latency_ms: p95_latency,
            p99_latency_ms: p99_latency,
            max_latency_ms: max_latency,
            throughput_msg_per_sec: throughput,
            error_rate_percent: error_rate,
            network_utilization: self.calculate_network_utilization(&latencies).await,
            node_metrics: self.collect_node_metrics().await,
            passed,
            failure_reason,
        })
    }

    /// ç½‘ç»œæ•…éšœæ¢å¤åŸºå‡†æµ‹è¯•
    async fn benchmark_network_recovery(&mut self) -> A2AResult<RealNetworkBenchmarkResult> {
        let test_name = "network_recovery".to_string();
        let start_time = SystemTime::now();

        info!("å¼€å§‹ç½‘ç»œæ•…éšœæ¢å¤åŸºå‡†æµ‹è¯•");

        // æ¨¡æ‹Ÿç½‘ç»œåˆ†åŒºï¼šå°†èŠ‚ç‚¹åˆ†ä¸ºä¸¤ç»„
        let mid_point = self.test_nodes.len() / 2;
        let (group1, group2) = self.test_nodes.split_at_mut(mid_point);

        // è®¾ç½®åˆ†åŒºçŠ¶æ€
        for node in group1.iter_mut() {
            node.status = NodeStatus::Partitioned;
        }

        let mut latencies = Vec::new();
        let mut successful_messages = 0;
        let mut failed_messages = 0;

        // é˜¶æ®µ1: ç½‘ç»œåˆ†åŒºæœŸé—´çš„é€šä¿¡æµ‹è¯•ï¼ˆé¢„æœŸå¤§éƒ¨åˆ†å¤±è´¥ï¼‰
        info!("é˜¶æ®µ1: ç½‘ç»œåˆ†åŒºæœŸé—´æµ‹è¯•");
        let partition_duration = Duration::from_secs(30);
        let partition_start = Instant::now();

        while partition_start.elapsed() < partition_duration {
            // å°è¯•è·¨åˆ†åŒºé€šä¿¡ï¼ˆåº”è¯¥å¤±è´¥ï¼‰
            let result = Self::simulate_cross_node_communication(
                &group1[0].address,
                &group2[0].address,
                &A2AMessage::new_text(MessageRole::Agent, "åˆ†åŒºæµ‹è¯•æ¶ˆæ¯".to_string()),
            ).await;

            match result {
                Ok(_) => successful_messages += 1,
                Err(_) => failed_messages += 1,
            }

            tokio::time::sleep(Duration::from_millis(100)).await;
        }

        // é˜¶æ®µ2: æ¢å¤ç½‘ç»œè¿æ¥
        info!("é˜¶æ®µ2: æ¢å¤ç½‘ç»œè¿æ¥");
        for node in group1.iter_mut() {
            node.status = NodeStatus::Online;
        }

        // ç­‰å¾…ç½‘ç»œæ¢å¤
        tokio::time::sleep(Duration::from_secs(5)).await;

        // é˜¶æ®µ3: æ¢å¤åçš„é€šä¿¡æµ‹è¯•
        info!("é˜¶æ®µ3: ç½‘ç»œæ¢å¤åæµ‹è¯•");
        let recovery_test_count = 100;

        for i in 0..recovery_test_count {
            let start = Instant::now();

            let result = Self::simulate_cross_node_communication(
                &group1[i % group1.len()].address,
                &group2[i % group2.len()].address,
                &A2AMessage::new_text(MessageRole::Agent, format!("æ¢å¤æµ‹è¯•æ¶ˆæ¯ {}", i)),
            ).await;

            let latency = start.elapsed();

            match result {
                Ok(_) => {
                    latencies.push(latency.as_secs_f64() * 1000.0);
                    successful_messages += 1;
                }
                Err(_) => failed_messages += 1,
            }
        }

        let duration = start_time.elapsed().unwrap();

        // è®¡ç®—ç»Ÿè®¡æ•°æ®
        let (avg_latency, p95_latency, p99_latency, max_latency) =
            Self::calculate_latency_stats(&latencies);

        let total_messages = successful_messages + failed_messages;
        let throughput = successful_messages as f64 / duration.as_secs_f64();
        let error_rate = (failed_messages as f64 / total_messages as f64) * 100.0;

        // æ£€æŸ¥æ¢å¤åçš„æ€§èƒ½
        let recovery_success_rate = if recovery_test_count > 0 {
            (latencies.len() as f64 / recovery_test_count as f64) * 100.0
        } else {
            0.0
        };

        let passed = recovery_success_rate > 95.0 && avg_latency < 100.0;
        let failure_reason = if !passed {
            Some(format!("ç½‘ç»œæ¢å¤æ€§èƒ½ä¸è¾¾æ ‡: æ¢å¤æˆåŠŸç‡ {:.1}%, å»¶è¿Ÿ {:.2}ms",
                        recovery_success_rate, avg_latency))
        } else {
            None
        };

        info!("ç½‘ç»œæ•…éšœæ¢å¤æµ‹è¯•å®Œæˆ: æ¢å¤æˆåŠŸç‡ {:.1}%, å¹³å‡å»¶è¿Ÿ {:.2}ms",
              recovery_success_rate, avg_latency);

        Ok(RealNetworkBenchmarkResult {
            test_name,
            start_time,
            duration,
            total_messages,
            successful_messages,
            failed_messages,
            avg_e2e_latency_ms: avg_latency,
            p95_latency_ms: p95_latency,
            p99_latency_ms: p99_latency,
            max_latency_ms: max_latency,
            throughput_msg_per_sec: throughput,
            error_rate_percent: error_rate,
            network_utilization: self.calculate_network_utilization(&latencies).await,
            node_metrics: self.collect_node_metrics().await,
            passed,
            failure_reason,
        })
    }

    /// é•¿æœŸç¨³å®šæ€§åŸºå‡†æµ‹è¯•
    async fn benchmark_long_term_stability(&mut self) -> A2AResult<RealNetworkBenchmarkResult> {
        let test_name = "long_term_stability".to_string();
        let start_time = SystemTime::now();

        info!("å¼€å§‹é•¿æœŸç¨³å®šæ€§åŸºå‡†æµ‹è¯•");

        let mut latencies = Vec::new();
        let mut successful_messages = 0;
        let mut failed_messages = 0;

        // é•¿æœŸæµ‹è¯•ï¼šæŒç»­å‘é€æ¶ˆæ¯å¹¶ç›‘æ§æ€§èƒ½å˜åŒ–
        let stability_duration = self.config.test_duration;
        let message_interval = Duration::from_millis((1000.0 / self.config.message_rate) as u64);
        let test_start = Instant::now();

        let mut performance_samples = Vec::new();
        let sample_interval = Duration::from_secs(30); // æ¯30ç§’é‡‡æ ·ä¸€æ¬¡
        let mut last_sample = Instant::now();

        while test_start.elapsed() < stability_duration {
            let round_start = Instant::now();

            // å‘é€ä¸€æ‰¹æ¶ˆæ¯
            let batch_size = 10;
            let mut batch_latencies = Vec::new();
            let mut batch_successes = 0;
            let mut batch_failures = 0;

            for i in 0..batch_size {
                let node_idx = i % self.test_nodes.len();
                let target_idx = (i + 1) % self.test_nodes.len();

                let message = A2AMessage::new_text(
                    MessageRole::Agent,
                    format!("ç¨³å®šæ€§æµ‹è¯•æ¶ˆæ¯ {}", successful_messages + failed_messages + i),
                );

                let msg_start = Instant::now();

                let result = Self::simulate_cross_node_communication(
                    &self.test_nodes[node_idx].address,
                    &self.test_nodes[target_idx].address,
                    &message,
                ).await;

                let latency = msg_start.elapsed();

                match result {
                    Ok(_) => {
                        batch_latencies.push(latency.as_secs_f64() * 1000.0);
                        batch_successes += 1;
                    }
                    Err(_) => batch_failures += 1,
                }
            }

            latencies.extend(batch_latencies.clone());
            successful_messages += batch_successes;
            failed_messages += batch_failures;

            // å®šæœŸé‡‡æ ·æ€§èƒ½æŒ‡æ ‡
            if last_sample.elapsed() >= sample_interval {
                let avg_batch_latency = if !batch_latencies.is_empty() {
                    batch_latencies.iter().sum::<f64>() / batch_latencies.len() as f64
                } else {
                    0.0
                };

                performance_samples.push((test_start.elapsed(), avg_batch_latency));
                last_sample = Instant::now();

                debug!("ç¨³å®šæ€§æµ‹è¯•è¿›åº¦: {:.1}%, å½“å‰å»¶è¿Ÿ: {:.2}ms",
                      (test_start.elapsed().as_secs_f64() / stability_duration.as_secs_f64()) * 100.0,
                      avg_batch_latency);
            }

            // æ§åˆ¶æ¶ˆæ¯å‘é€é¢‘ç‡
            let elapsed = round_start.elapsed();
            if elapsed < message_interval {
                tokio::time::sleep(message_interval - elapsed).await;
            }
        }

        let duration = start_time.elapsed().unwrap();

        // åˆ†ææ€§èƒ½ç¨³å®šæ€§
        let stability_analysis = Self::analyze_performance_stability(&performance_samples);

        // è®¡ç®—ç»Ÿè®¡æ•°æ®
        let (avg_latency, p95_latency, p99_latency, max_latency) =
            Self::calculate_latency_stats(&latencies);

        let total_messages = successful_messages + failed_messages;
        let throughput = successful_messages as f64 / duration.as_secs_f64();
        let error_rate = (failed_messages as f64 / total_messages as f64) * 100.0;

        // æ£€æŸ¥é•¿æœŸç¨³å®šæ€§
        let passed = stability_analysis.is_stable &&
                    avg_latency < 20.0 &&
                    error_rate < 2.0 &&
                    stability_analysis.performance_degradation < 50.0; // æ€§èƒ½é€€åŒ– < 50%

        let failure_reason = if !passed {
            Some(format!("é•¿æœŸç¨³å®šæ€§æµ‹è¯•å¤±è´¥: ç¨³å®šæ€§ {}, å»¶è¿Ÿ {:.2}ms, é”™è¯¯ç‡ {:.2}%, æ€§èƒ½é€€åŒ– {:.1}%",
                        stability_analysis.is_stable, avg_latency, error_rate,
                        stability_analysis.performance_degradation))
        } else {
            None
        };

        info!("é•¿æœŸç¨³å®šæ€§æµ‹è¯•å®Œæˆ: å¹³å‡å»¶è¿Ÿ {:.2}ms, ååé‡ {:.0} msg/s, é”™è¯¯ç‡ {:.2}%, æ€§èƒ½é€€åŒ– {:.1}%",
              avg_latency, throughput, error_rate, stability_analysis.performance_degradation);

        Ok(RealNetworkBenchmarkResult {
            test_name,
            start_time,
            duration,
            total_messages: total_messages as u64,
            successful_messages: successful_messages as u64,
            failed_messages: failed_messages as u64,
            avg_e2e_latency_ms: avg_latency,
            p95_latency_ms: p95_latency,
            p99_latency_ms: p99_latency,
            max_latency_ms: max_latency,
            throughput_msg_per_sec: throughput,
            error_rate_percent: error_rate,
            network_utilization: self.calculate_network_utilization(&latencies).await,
            node_metrics: self.collect_node_metrics().await,
            passed,
            failure_reason,
        })
    }

    // è¾…åŠ©æ–¹æ³•

    /// åˆå§‹åŒ–æµ‹è¯•èŠ‚ç‚¹
    async fn initialize_test_nodes(config: &RealNetworkConfig) -> A2AResult<Vec<TestNode>> {
        let mut nodes = Vec::new();
        let base_port = 8000;

        for i in 0..config.node_count {
            let node_id = format!("node_{}", i);
            let address = SocketAddr::new(
                IpAddr::V4(Ipv4Addr::new(127, 0, 0, 1)),
                base_port + i as u16,
            );

            let mut agents = Vec::new();
            for j in 0..config.agents_per_node {
                agents.push(format!("agent_{}_{}", i, j));
            }

            let node = TestNode {
                node_id,
                address,
                agents,
                status: NodeStatus::Online,
                metrics: NodeMetrics::default(),
            };

            nodes.push(node);
        }

        Ok(nodes)
    }

    /// è®¡ç®—å»¶è¿Ÿç»Ÿè®¡æ•°æ®
    fn calculate_latency_stats(latencies: &[f64]) -> (f64, f64, f64, f64) {
        if latencies.is_empty() {
            return (0.0, 0.0, 0.0, 0.0);
        }

        let mut sorted_latencies = latencies.to_vec();
        sorted_latencies.sort_by(|a, b| a.partial_cmp(b).unwrap());

        let avg = sorted_latencies.iter().sum::<f64>() / sorted_latencies.len() as f64;
        let p95_idx = (sorted_latencies.len() as f64 * 0.95) as usize;
        let p99_idx = (sorted_latencies.len() as f64 * 0.99) as usize;

        let p95 = sorted_latencies.get(p95_idx).copied().unwrap_or(0.0);
        let p99 = sorted_latencies.get(p99_idx).copied().unwrap_or(0.0);
        let max = sorted_latencies.last().copied().unwrap_or(0.0);

        (avg, p95, p99, max)
    }

    /// æ¨¡æ‹Ÿè·¨èŠ‚ç‚¹é€šä¿¡
    async fn simulate_cross_node_communication(
        source: &SocketAddr,
        target: &SocketAddr,
        _message: &A2AMessage,
    ) -> A2AResult<()> {
        // æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        tokio::time::sleep(Duration::from_millis(1)).await;

        // æ¨¡æ‹Ÿç½‘ç»œè¿æ¥ï¼ˆç®€åŒ–å®ç°ï¼‰
        if source.port() != target.port() {
            // æ¨¡æ‹ŸæˆåŠŸçš„è·¨èŠ‚ç‚¹é€šä¿¡
            Ok(())
        } else {
            Err(A2AError::internal("åŒèŠ‚ç‚¹é€šä¿¡".to_string()))
        }
    }

    /// æ¨¡æ‹Ÿè·¯ç”±å™¨æ¶ˆæ¯å‘é€
    async fn simulate_router_message_send(_message: A2AMessage) -> A2AResult<()> {
        // æ¨¡æ‹Ÿè·¯ç”±å»¶è¿Ÿ
        tokio::time::sleep(Duration::from_millis(1)).await;

        // æ¨¡æ‹ŸæˆåŠŸçš„æ¶ˆæ¯è·¯ç”±
        Ok(())
    }

    /// è®¡ç®—ç½‘ç»œåˆ©ç”¨ç‡
    async fn calculate_network_utilization(&self, latencies: &[f64]) -> NetworkUtilization {
        let latency_distribution = if !latencies.is_empty() {
            let mut sorted = latencies.to_vec();
            sorted.sort_by(|a, b| a.partial_cmp(b).unwrap());

            let min = sorted.first().copied().unwrap_or(0.0);
            let max = sorted.last().copied().unwrap_or(0.0);
            let avg = sorted.iter().sum::<f64>() / sorted.len() as f64;

            // è®¡ç®—æ ‡å‡†å·®
            let variance = sorted.iter()
                .map(|x| (x - avg).powi(2))
                .sum::<f64>() / sorted.len() as f64;
            let std_dev = variance.sqrt();

            let mut percentiles = HashMap::new();
            percentiles.insert("P50".to_string(), sorted[sorted.len() / 2]);
            percentiles.insert("P90".to_string(), sorted[(sorted.len() as f64 * 0.9) as usize]);
            percentiles.insert("P95".to_string(), sorted[(sorted.len() as f64 * 0.95) as usize]);
            percentiles.insert("P99".to_string(), sorted[(sorted.len() as f64 * 0.99) as usize]);

            LatencyDistribution {
                min_ms: min,
                max_ms: max,
                avg_ms: avg,
                std_dev_ms: std_dev,
                percentiles,
            }
        } else {
            LatencyDistribution {
                min_ms: 0.0,
                max_ms: 0.0,
                avg_ms: 0.0,
                std_dev_ms: 0.0,
                percentiles: HashMap::new(),
            }
        };

        NetworkUtilization {
            avg_bandwidth_mbps: 50.0, // æ¨¡æ‹Ÿå€¼
            peak_bandwidth_mbps: 80.0, // æ¨¡æ‹Ÿå€¼
            latency_distribution,
            packet_loss_stats: PacketLossStats {
                total_packets: latencies.len() as u64,
                lost_packets: 0, // ç®€åŒ–å®ç°
                loss_rate_percent: 0.0,
                retransmissions: 0,
            },
        }
    }

    /// æ”¶é›†èŠ‚ç‚¹æ€§èƒ½æŒ‡æ ‡
    async fn collect_node_metrics(&self) -> HashMap<String, NodeMetrics> {
        let mut metrics = HashMap::new();

        for node in &self.test_nodes {
            metrics.insert(node.node_id.clone(), node.metrics.clone());
        }

        metrics
    }

    /// åˆ†ææ€§èƒ½ç¨³å®šæ€§
    fn analyze_performance_stability(samples: &[(Duration, f64)]) -> StabilityAnalysis {
        if samples.len() < 2 {
            return StabilityAnalysis {
                is_stable: false,
                performance_degradation: 100.0,
                trend: "insufficient_data".to_string(),
            };
        }

        let first_half = &samples[..samples.len() / 2];
        let second_half = &samples[samples.len() / 2..];

        let first_avg = first_half.iter().map(|(_, latency)| latency).sum::<f64>() / first_half.len() as f64;
        let second_avg = second_half.iter().map(|(_, latency)| latency).sum::<f64>() / second_half.len() as f64;

        let degradation = if first_avg > 0.0 {
            ((second_avg - first_avg) / first_avg) * 100.0
        } else {
            0.0
        };

        let is_stable = degradation < 20.0; // æ€§èƒ½é€€åŒ–å°äº20%è®¤ä¸ºç¨³å®š
        let trend = if degradation > 10.0 {
            "degrading".to_string()
        } else if degradation < -10.0 {
            "improving".to_string()
        } else {
            "stable".to_string()
        };

        StabilityAnalysis {
            is_stable,
            performance_degradation: degradation.max(0.0),
            trend,
        }
    }
}

/// ç¨³å®šæ€§åˆ†æç»“æœ
#[derive(Debug, Clone)]
struct StabilityAnalysis {
    /// æ˜¯å¦ç¨³å®š
    is_stable: bool,
    /// æ€§èƒ½é€€åŒ–ç™¾åˆ†æ¯”
    performance_degradation: f64,
    /// è¶‹åŠ¿
    #[allow(dead_code)]
    trend: String,
}

impl NetworkSimulator {
    /// åˆ›å»ºæ–°çš„ç½‘ç»œæ¨¡æ‹Ÿå™¨
    pub fn new(latency_ms: u64, packet_loss_rate: f64, jitter_ms: u64, bandwidth_limit: Option<f64>) -> Self {
        Self {
            latency_ms,
            packet_loss_rate,
            jitter_ms,
            bandwidth_limit,
        }
    }

    /// æ¨¡æ‹Ÿæ¶ˆæ¯ä¼ è¾“
    pub async fn simulate_message_transmission(
        &self,
        _message: &A2AMessage,
        _source: &SocketAddr,
        _target: &SocketAddr,
    ) -> A2AResult<()> {
        // æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        let base_latency = Duration::from_millis(self.latency_ms);

        // æ·»åŠ æŠ–åŠ¨
        let jitter = if self.jitter_ms > 0 {
            Duration::from_millis(rand::random::<u64>() % self.jitter_ms)
        } else {
            Duration::ZERO
        };

        tokio::time::sleep(base_latency + jitter).await;

        // æ¨¡æ‹Ÿä¸¢åŒ…
        if rand::random::<f64>() < self.packet_loss_rate / 100.0 {
            return Err(A2AError::internal("æ¨¡æ‹Ÿä¸¢åŒ…".to_string()));
        }

        Ok(())
    }
}

impl Clone for NetworkSimulator {
    fn clone(&self) -> Self {
        Self {
            latency_ms: self.latency_ms,
            packet_loss_rate: self.packet_loss_rate,
            jitter_ms: self.jitter_ms,
            bandwidth_limit: self.bandwidth_limit,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_real_network_benchmarks_creation() {
        let config = RealNetworkConfig::default();
        let benchmarks = RealNetworkBenchmarks::new(config).await;
        assert!(benchmarks.is_ok());
    }

    #[tokio::test]
    async fn test_network_latency_benchmark() {
        let config = RealNetworkConfig {
            node_count: 2,
            agents_per_node: 2,
            test_duration: Duration::from_secs(10),
            message_rate: 10.0,
            ..Default::default()
        };

        let mut benchmarks = RealNetworkBenchmarks::new(config).await.unwrap();
        let result = benchmarks.benchmark_network_latency().await;
        assert!(result.is_ok());

        let benchmark_result = result.unwrap();
        assert_eq!(benchmark_result.test_name, "network_latency");
        assert!(benchmark_result.total_messages > 0);
    }

    #[test]
    fn test_latency_stats_calculation() {
        let latencies = vec![1.0, 2.0, 3.0, 4.0, 5.0, 10.0, 15.0, 20.0, 25.0, 30.0];
        let (avg, p95, p99, max) = RealNetworkBenchmarks::calculate_latency_stats(&latencies);

        assert!((avg - 11.5).abs() < 0.1);
        assert!(p95 > 20.0);
        assert!(p99 > 25.0);
        assert_eq!(max, 30.0);
    }

    #[test]
    fn test_stability_analysis() {
        let samples = vec![
            (Duration::from_secs(0), 5.0),
            (Duration::from_secs(30), 5.2),
            (Duration::from_secs(60), 5.1),
            (Duration::from_secs(90), 5.3),
        ];

        let analysis = RealNetworkBenchmarks::analyze_performance_stability(&samples);
        assert!(analysis.is_stable);
        assert!(analysis.performance_degradation < 10.0);
    }
}
