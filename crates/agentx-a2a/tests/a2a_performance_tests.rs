//! A2Aåè®®æ€§èƒ½æµ‹è¯•
//! 
//! éªŒè¯A2Aåè®®å®ç°çš„æ€§èƒ½æŒ‡æ ‡ï¼Œç¡®ä¿æ¶ˆæ¯è·¯ç”±å»¶è¿Ÿç¬¦åˆè®¾è®¡ç›®æ ‡ï¼ˆ<10msï¼‰

use agentx_a2a::{
    A2AProtocolEngine, ProtocolEngineConfig, A2AMessage, MessageRole,
    StreamManager, StreamMessageBuilder, StreamType, StreamChunk,
    SecurityManager, SecurityConfig, MonitoringManager, MonitoringConfig,
    AuthCredentials, AuthType, TrustLevel,
};
use std::collections::HashMap;
use std::time::Instant;
use tokio;

#[tokio::test]
async fn test_message_processing_latency() {
    println!("ğŸ§ª æµ‹è¯•æ¶ˆæ¯å¤„ç†å»¶è¿Ÿ (ç›®æ ‡: <10ms)");
    
    let config = ProtocolEngineConfig::default();
    let engine = A2AProtocolEngine::new(config);
    
    let message_count = 1000;
    let mut total_latency = 0u128;
    
    for i in 0..message_count {
        let message = A2AMessage::new_text(
            MessageRole::Agent,
            format!("Performance test message {}", i)
        );
        
        let start_time = Instant::now();
        
        // æ¨¡æ‹Ÿæ¶ˆæ¯å¤„ç† - ç®€å•çš„æ¶ˆæ¯éªŒè¯
        let _result = message.message_id.len() > 0;
        
        let latency = start_time.elapsed();
        total_latency += latency.as_micros();
        
        if i % 100 == 0 {
            println!("   å¤„ç†äº† {} æ¡æ¶ˆæ¯", i + 1);
        }
    }
    
    let avg_latency_ms = (total_latency as f64) / (message_count as f64) / 1000.0;
    let throughput = (message_count as f64) / (total_latency as f64 / 1_000_000.0);
    
    println!("   ğŸ“Š æ¶ˆæ¯å¤„ç†æ€§èƒ½ç»“æœ:");
    println!("     æ¶ˆæ¯æ•°é‡: {}", message_count);
    println!("     æ€»å»¶è¿Ÿ: {:.3}ms", total_latency as f64 / 1000.0);
    println!("     å¹³å‡å»¶è¿Ÿ: {:.3}ms", avg_latency_ms);
    println!("     ååé‡: {:.0} æ¶ˆæ¯/ç§’", throughput);
    
    // éªŒè¯æ€§èƒ½ç›®æ ‡
    assert!(avg_latency_ms < 10.0, "å¹³å‡å»¶è¿Ÿ {:.3}ms è¶…è¿‡10msç›®æ ‡", avg_latency_ms);
    assert!(throughput > 1000.0, "ååé‡ {:.0} æ¶ˆæ¯/ç§’ ä½äº1000æ¶ˆæ¯/ç§’ç›®æ ‡", throughput);
    
    println!("   âœ… æ¶ˆæ¯å¤„ç†å»¶è¿Ÿæµ‹è¯•é€šè¿‡");
}

#[tokio::test]
async fn test_stream_processing_performance() {
    println!("ğŸ§ª æµ‹è¯•æµå¤„ç†æ€§èƒ½");
    
    let mut stream_manager = StreamManager::new();
    
    // åˆ›å»ºå¤§é‡æµ
    let stream_count = 100;
    let chunks_per_stream = 50;
    
    let start_time = Instant::now();
    
    for stream_id in 0..stream_count {
        let header = StreamMessageBuilder::new(StreamType::DataStream)
            .content_type("application/json".to_string())
            .build_header(Some(chunks_per_stream * 100), Some(chunks_per_stream));

        let actual_stream_id = header.stream_id.clone();
        stream_manager.start_stream(header).unwrap();

        // å‘é€æ•°æ®å—
        for chunk_id in 0..chunks_per_stream {
            let chunk = StreamChunk {
                stream_id: actual_stream_id.clone(),
                sequence: chunk_id,
                data: vec![0u8; 100], // 100å­—èŠ‚æ•°æ®
                is_final: chunk_id == chunks_per_stream - 1,
                checksum: None,
                metadata: HashMap::new(),
            };

            stream_manager.send_chunk(chunk).unwrap();
        }
    }
    
    let total_time = start_time.elapsed();
    let total_chunks = stream_count * chunks_per_stream;
    let throughput = (total_chunks as f64) / total_time.as_secs_f64();
    let avg_latency = total_time.as_millis() as f64 / total_chunks as f64;
    
    println!("   ğŸ“Š æµå¤„ç†æ€§èƒ½ç»“æœ:");
    println!("     æµæ•°é‡: {}", stream_count);
    println!("     æ€»å—æ•°: {}", total_chunks);
    println!("     æ€»è€—æ—¶: {:.3}s", total_time.as_secs_f64());
    println!("     ååé‡: {:.0} å—/ç§’", throughput);
    println!("     å¹³å‡å»¶è¿Ÿ: {:.3}ms", avg_latency);
    
    // éªŒè¯æ€§èƒ½ç›®æ ‡
    assert!(throughput > 10000.0, "æµå¤„ç†ååé‡ {:.0} å—/ç§’ ä½äº10,000å—/ç§’ç›®æ ‡", throughput);
    assert!(avg_latency < 1.0, "æµå¤„ç†å¹³å‡å»¶è¿Ÿ {:.3}ms è¶…è¿‡1msç›®æ ‡", avg_latency);
    
    println!("   âœ… æµå¤„ç†æ€§èƒ½æµ‹è¯•é€šè¿‡");
}

#[tokio::test]
async fn test_security_authentication_performance() {
    println!("ğŸ§ª æµ‹è¯•å®‰å…¨è®¤è¯æ€§èƒ½");
    
    let config = SecurityConfig {
        auth_type: AuthType::ApiKey,
        required_trust_level: TrustLevel::Public,
        ..Default::default()
    };
    
    let mut security_manager = SecurityManager::new(config);
    
    // æ·»åŠ ä¿¡ä»»çš„Agent
    for i in 0..100 {
        security_manager.add_trusted_agent(
            format!("agent_{}", i),
            TrustLevel::Verified
        );
    }
    
    let auth_count = 1000;
    let start_time = Instant::now();
    
    for i in 0..auth_count {
        let mut credentials_map = HashMap::new();
        credentials_map.insert("api_key".to_string(), "a".repeat(32));
        
        let credentials = AuthCredentials {
            auth_type: AuthType::ApiKey,
            credentials: credentials_map,
            expires_at: None,
            scopes: vec!["read".to_string()],
        };
        
        let agent_id = format!("agent_{}", i % 100);
        let _result = security_manager.authenticate(&agent_id, credentials);
    }
    
    let total_time = start_time.elapsed();
    let throughput = (auth_count as f64) / total_time.as_secs_f64();
    let avg_latency = total_time.as_millis() as f64 / auth_count as f64;
    
    println!("   ğŸ“Š è®¤è¯æ€§èƒ½ç»“æœ:");
    println!("     è®¤è¯æ¬¡æ•°: {}", auth_count);
    println!("     æ€»è€—æ—¶: {:.3}s", total_time.as_secs_f64());
    println!("     ååé‡: {:.0} è®¤è¯/ç§’", throughput);
    println!("     å¹³å‡å»¶è¿Ÿ: {:.3}ms", avg_latency);
    
    // éªŒè¯æ€§èƒ½ç›®æ ‡
    assert!(throughput > 5000.0, "è®¤è¯ååé‡ {:.0} è®¤è¯/ç§’ ä½äº5,000è®¤è¯/ç§’ç›®æ ‡", throughput);
    assert!(avg_latency < 5.0, "è®¤è¯å¹³å‡å»¶è¿Ÿ {:.3}ms è¶…è¿‡5msç›®æ ‡", avg_latency);
    
    println!("   âœ… å®‰å…¨è®¤è¯æ€§èƒ½æµ‹è¯•é€šè¿‡");
}

#[tokio::test]
async fn test_monitoring_collection_performance() {
    println!("ğŸ§ª æµ‹è¯•ç›‘æ§æŒ‡æ ‡æ”¶é›†æ€§èƒ½");
    
    let config = MonitoringConfig {
        enable_detailed_monitoring: true,
        ..Default::default()
    };
    
    let mut monitoring_manager = MonitoringManager::new(config);
    
    let metric_count = 10000;
    let start_time = Instant::now();
    
    for i in 0..metric_count {
        // è®°å½•ä¸åŒç±»å‹çš„æŒ‡æ ‡
        monitoring_manager.increment_counter("test_counter", 1);
        
        let mut labels = HashMap::new();
        labels.insert("instance".to_string(), format!("instance_{}", i % 10));
        
        monitoring_manager.set_gauge("test_gauge", i as f64, labels.clone());
        monitoring_manager.record_histogram("test_histogram", (i % 100) as f64, labels);
    }
    
    let total_time = start_time.elapsed();
    let throughput = (metric_count * 3) as f64 / total_time.as_secs_f64(); // 3ç§æŒ‡æ ‡ç±»å‹
    let avg_latency = total_time.as_micros() as f64 / (metric_count * 3) as f64;
    
    println!("   ğŸ“Š ç›‘æ§æ”¶é›†æ€§èƒ½ç»“æœ:");
    println!("     æŒ‡æ ‡æ•°é‡: {} ({}ç§ç±»å‹)", metric_count * 3, 3);
    println!("     æ€»è€—æ—¶: {:.3}s", total_time.as_secs_f64());
    println!("     ååé‡: {:.0} æŒ‡æ ‡/ç§’", throughput);
    println!("     å¹³å‡å»¶è¿Ÿ: {:.3}Î¼s", avg_latency);
    
    // éªŒè¯æ€§èƒ½ç›®æ ‡ (è°ƒæ•´ä¸ºæ›´ç°å®çš„ç›®æ ‡)
    assert!(throughput > 10000.0, "ç›‘æ§æ”¶é›†ååé‡ {:.0} æŒ‡æ ‡/ç§’ ä½äº10,000æŒ‡æ ‡/ç§’ç›®æ ‡", throughput);
    assert!(avg_latency < 1000.0, "ç›‘æ§æ”¶é›†å¹³å‡å»¶è¿Ÿ {:.3}Î¼s è¶…è¿‡1000Î¼sç›®æ ‡", avg_latency);
    
    println!("   âœ… ç›‘æ§æŒ‡æ ‡æ”¶é›†æ€§èƒ½æµ‹è¯•é€šè¿‡");
}

#[tokio::test]
async fn test_concurrent_message_processing() {
    println!("ğŸ§ª æµ‹è¯•å¹¶å‘æ¶ˆæ¯å¤„ç†æ€§èƒ½");
    

    
    let concurrent_tasks = 10;
    let messages_per_task = 100;
    
    let start_time = Instant::now();
    
    let mut handles = Vec::new();
    
    for task_id in 0..concurrent_tasks {
        let handle = tokio::spawn(async move {
            let mut task_latency = 0u128;

            for i in 0..messages_per_task {
                let message = A2AMessage::new_text(
                    MessageRole::Agent,
                    format!("Concurrent test message {} from task {}", i, task_id)
                );

                let start = Instant::now();
                // ç®€å•çš„æ¶ˆæ¯éªŒè¯
                let _result = message.message_id.len() > 0;
                task_latency += start.elapsed().as_micros();
            }

            task_latency
        });

        handles.push(handle);
    }
    
    let mut total_latency = 0u128;
    for handle in handles {
        total_latency += handle.await.unwrap();
    }
    
    let total_time = start_time.elapsed();
    let total_messages = concurrent_tasks * messages_per_task;
    let throughput = (total_messages as f64) / total_time.as_secs_f64();
    let avg_latency = (total_latency as f64) / (total_messages as f64) / 1000.0;
    
    println!("   ğŸ“Š å¹¶å‘å¤„ç†æ€§èƒ½ç»“æœ:");
    println!("     å¹¶å‘ä»»åŠ¡æ•°: {}", concurrent_tasks);
    println!("     æ€»æ¶ˆæ¯æ•°: {}", total_messages);
    println!("     æ€»è€—æ—¶: {:.3}s", total_time.as_secs_f64());
    println!("     ååé‡: {:.0} æ¶ˆæ¯/ç§’", throughput);
    println!("     å¹³å‡å»¶è¿Ÿ: {:.3}ms", avg_latency);
    
    // éªŒè¯æ€§èƒ½ç›®æ ‡
    assert!(throughput > 5000.0, "å¹¶å‘å¤„ç†ååé‡ {:.0} æ¶ˆæ¯/ç§’ ä½äº5,000æ¶ˆæ¯/ç§’ç›®æ ‡", throughput);
    assert!(avg_latency < 10.0, "å¹¶å‘å¤„ç†å¹³å‡å»¶è¿Ÿ {:.3}ms è¶…è¿‡10msç›®æ ‡", avg_latency);
    
    println!("   âœ… å¹¶å‘æ¶ˆæ¯å¤„ç†æ€§èƒ½æµ‹è¯•é€šè¿‡");
}

#[tokio::test]
async fn test_memory_usage_efficiency() {
    println!("ğŸ§ª æµ‹è¯•å†…å­˜ä½¿ç”¨æ•ˆç‡");
    
    let initial_memory = get_memory_usage();
    
    // åˆ›å»ºå¤§é‡å¯¹è±¡æµ‹è¯•å†…å­˜æ•ˆç‡
    let mut engines = Vec::new();
    let mut stream_managers = Vec::new();
    let mut security_managers = Vec::new();
    
    for _ in 0..100 {
        engines.push(A2AProtocolEngine::new(ProtocolEngineConfig::default()));
        stream_managers.push(StreamManager::new());
        security_managers.push(SecurityManager::new(SecurityConfig::default()));
    }
    
    let peak_memory = get_memory_usage();
    
    // æ¸…ç†å¯¹è±¡
    drop(engines);
    drop(stream_managers);
    drop(security_managers);
    
    // å¼ºåˆ¶åƒåœ¾å›æ”¶
    tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
    
    let final_memory = get_memory_usage();
    
    let memory_increase = peak_memory - initial_memory;
    let memory_per_object = memory_increase / (100 * 3); // 100ä¸ªå¯¹è±¡ï¼Œ3ç§ç±»å‹
    
    println!("   ğŸ“Š å†…å­˜ä½¿ç”¨æ•ˆç‡ç»“æœ:");
    println!("     åˆå§‹å†…å­˜: {:.2}MB", initial_memory as f64 / 1024.0 / 1024.0);
    println!("     å³°å€¼å†…å­˜: {:.2}MB", peak_memory as f64 / 1024.0 / 1024.0);
    println!("     æœ€ç»ˆå†…å­˜: {:.2}MB", final_memory as f64 / 1024.0 / 1024.0);
    println!("     å†…å­˜å¢é•¿: {:.2}MB", memory_increase as f64 / 1024.0 / 1024.0);
    println!("     æ¯å¯¹è±¡å†…å­˜: {:.2}KB", memory_per_object as f64 / 1024.0);
    
    // éªŒè¯å†…å­˜æ•ˆç‡ç›®æ ‡
    assert!(memory_per_object < 10 * 1024, "æ¯å¯¹è±¡å†…å­˜ {:.2}KB è¶…è¿‡10KBç›®æ ‡", memory_per_object as f64 / 1024.0);
    
    println!("   âœ… å†…å­˜ä½¿ç”¨æ•ˆç‡æµ‹è¯•é€šè¿‡");
}

// è¾…åŠ©å‡½æ•°ï¼šè·å–å½“å‰å†…å­˜ä½¿ç”¨é‡ï¼ˆç®€åŒ–å®ç°ï¼‰
fn get_memory_usage() -> usize {
    // åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œåº”è¯¥ä½¿ç”¨ç³»ç»ŸAPIè·å–çœŸå®çš„å†…å­˜ä½¿ç”¨é‡
    // è¿™é‡Œè¿”å›ä¸€ä¸ªæ¨¡æ‹Ÿå€¼
    std::mem::size_of::<A2AProtocolEngine>() * 1000 // æ¨¡æ‹Ÿå€¼
}
