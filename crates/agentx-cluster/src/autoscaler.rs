//! è‡ªåŠ¨æ‰©ç¼©å®¹ç®¡ç†å™¨
//! 
//! åŸºäºè´Ÿè½½å’Œæ€§èƒ½æŒ‡æ ‡è‡ªåŠ¨è°ƒæ•´é›†ç¾¤è§„æ¨¡

use crate::config::AutoscalerConfig;
use crate::error::{ClusterError, ClusterResult};
use crate::cluster_state::ClusterState;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;
use tracing::{debug, info};
use chrono::{DateTime, Utc, Duration};

/// æ‰©ç¼©å®¹åŠ¨ä½œ
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub enum ScalingAction {
    /// æ‰©å®¹
    ScaleUp {
        /// ç›®æ ‡å®ä¾‹æ•°
        target_instances: u32,
        /// æ‰©å®¹åŸå› 
        reason: String,
    },
    /// ç¼©å®¹
    ScaleDown {
        /// ç›®æ ‡å®ä¾‹æ•°
        target_instances: u32,
        /// ç¼©å®¹åŸå› 
        reason: String,
    },
    /// æ— éœ€æ“ä½œ
    NoAction,
}

/// æ‰©ç¼©å®¹å†³ç­–
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ScalingDecision {
    /// å†³ç­–æ—¶é—´
    pub timestamp: DateTime<Utc>,
    /// å½“å‰å®ä¾‹æ•°
    pub current_instances: u32,
    /// å»ºè®®åŠ¨ä½œ
    pub action: ScalingAction,
    /// å†³ç­–ä¾æ®çš„æŒ‡æ ‡
    pub metrics: HashMap<String, f64>,
    /// å†³ç­–ç½®ä¿¡åº¦ (0.0-1.0)
    pub confidence: f64,
}

/// æ‰©ç¼©å®¹å†å²è®°å½•
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ScalingHistory {
    /// è®°å½•æ—¶é—´
    pub timestamp: DateTime<Utc>,
    /// æ‰§è¡Œçš„åŠ¨ä½œ
    pub action: ScalingAction,
    /// æ‰§è¡Œå‰å®ä¾‹æ•°
    pub before_instances: u32,
    /// æ‰§è¡Œåå®ä¾‹æ•°
    pub after_instances: u32,
    /// æ‰§è¡Œç»“æœ
    pub success: bool,
    /// é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰
    pub error_message: Option<String>,
}

/// æ€§èƒ½æŒ‡æ ‡
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceMetrics {
    /// CPUä½¿ç”¨ç‡ (0.0-1.0)
    pub cpu_usage: f64,
    /// å†…å­˜ä½¿ç”¨ç‡ (0.0-1.0)
    pub memory_usage: f64,
    /// å¹³å‡å“åº”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    pub avg_response_time: f64,
    /// æ¶ˆæ¯é˜Ÿåˆ—é•¿åº¦
    pub queue_length: u32,
    /// é”™è¯¯ç‡ (0.0-1.0)
    pub error_rate: f64,
    /// ååé‡ï¼ˆæ¶ˆæ¯/ç§’ï¼‰
    pub throughput: f64,
    /// è‡ªå®šä¹‰æŒ‡æ ‡
    pub custom_metrics: HashMap<String, f64>,
}

impl Default for PerformanceMetrics {
    fn default() -> Self {
        Self {
            cpu_usage: 0.0,
            memory_usage: 0.0,
            avg_response_time: 0.0,
            queue_length: 0,
            error_rate: 0.0,
            throughput: 0.0,
            custom_metrics: HashMap::new(),
        }
    }
}

/// è‡ªåŠ¨æ‰©ç¼©å®¹ç®¡ç†å™¨
pub struct AutoScaler {
    /// é…ç½®
    config: AutoscalerConfig,
    /// å½“å‰æ€§èƒ½æŒ‡æ ‡
    current_metrics: Arc<RwLock<PerformanceMetrics>>,
    /// æ‰©ç¼©å®¹å†å²
    scaling_history: Arc<RwLock<Vec<ScalingHistory>>>,
    /// æœ€åæ‰©ç¼©å®¹æ—¶é—´
    last_scaling_time: Arc<RwLock<Option<DateTime<Utc>>>>,
    /// æ˜¯å¦è¿è¡Œä¸­
    running: Arc<RwLock<bool>>,
}

impl AutoScaler {
    /// åˆ›å»ºæ–°çš„è‡ªåŠ¨æ‰©ç¼©å®¹ç®¡ç†å™¨
    pub fn new(config: AutoscalerConfig) -> Self {
        info!("ğŸ”§ åˆ›å»ºè‡ªåŠ¨æ‰©ç¼©å®¹ç®¡ç†å™¨ï¼Œç­–ç•¥: {:?}", config.strategy);
        
        Self {
            config,
            current_metrics: Arc::new(RwLock::new(PerformanceMetrics::default())),
            scaling_history: Arc::new(RwLock::new(Vec::new())),
            last_scaling_time: Arc::new(RwLock::new(None)),
            running: Arc::new(RwLock::new(false)),
        }
    }

    /// å¯åŠ¨è‡ªåŠ¨æ‰©ç¼©å®¹
    pub async fn start(&self) -> ClusterResult<()> {
        {
            let mut running = self.running.write().await;
            if *running {
                return Err(ClusterError::AlreadyRunning("AutoScalerå·²åœ¨è¿è¡Œ".to_string()));
            }
            *running = true;
        }

        info!("ğŸš€ å¯åŠ¨è‡ªåŠ¨æ‰©ç¼©å®¹ç®¡ç†å™¨");

        // å¯åŠ¨æŒ‡æ ‡æ”¶é›†ä»»åŠ¡
        self.start_metrics_collection().await?;

        // å¯åŠ¨æ‰©ç¼©å®¹å†³ç­–ä»»åŠ¡
        self.start_scaling_decision().await?;

        Ok(())
    }

    /// åœæ­¢è‡ªåŠ¨æ‰©ç¼©å®¹
    pub async fn stop(&self) -> ClusterResult<()> {
        {
            let mut running = self.running.write().await;
            *running = false;
        }

        info!("ğŸ›‘ åœæ­¢è‡ªåŠ¨æ‰©ç¼©å®¹ç®¡ç†å™¨");
        Ok(())
    }

    /// æ›´æ–°æ€§èƒ½æŒ‡æ ‡
    pub async fn update_metrics(&self, metrics: PerformanceMetrics) -> ClusterResult<()> {
        {
            let mut current_metrics = self.current_metrics.write().await;
            *current_metrics = metrics;
        }

        debug!("ğŸ“Š æ›´æ–°æ€§èƒ½æŒ‡æ ‡");
        Ok(())
    }

    /// åŸºäºé›†ç¾¤çŠ¶æ€æ›´æ–°æŒ‡æ ‡
    pub async fn update_metrics_from_cluster_state(&self, _cluster_state: &ClusterState) -> ClusterResult<()> {
        // æ³¨æ„ï¼šClusterStateæœ¬èº«ä¸åŒ…å«è¯¦ç»†çš„agentç»Ÿè®¡ä¿¡æ¯
        // è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ç®€åŒ–çš„æŒ‡æ ‡è®¡ç®—ï¼Œå®é™…åº”è¯¥ä»ClusterStateManagerè·å–è¯¦ç»†ä¿¡æ¯
        let mut metrics = PerformanceMetrics::default();

        // åŸºäºé›†ç¾¤åŸºæœ¬ä¿¡æ¯ä¼°ç®—æŒ‡æ ‡
        let agent_count = _cluster_state.agent_count as f64;

        // æ¨¡æ‹ŸCPUå’Œå†…å­˜ä½¿ç”¨ç‡ï¼ˆå®é™…åº”è¯¥ä»ç³»ç»Ÿç›‘æ§è·å–ï¼‰
        metrics.cpu_usage = (agent_count / 10.0).min(1.0);
        metrics.memory_usage = (agent_count / 15.0).min(1.0);

        // æ¨¡æ‹Ÿå“åº”æ—¶é—´ï¼ˆåŸºäºé›†ç¾¤è´Ÿè½½ï¼‰
        metrics.avg_response_time = if agent_count > 5.0 { 200.0 } else { 100.0 };

        // æ¨¡æ‹Ÿååé‡
        metrics.throughput = agent_count * 100.0;

        // æ¨¡æ‹Ÿé”™è¯¯ç‡
        metrics.error_rate = if agent_count > 8.0 { 0.05 } else { 0.01 };

        self.update_metrics(metrics).await
    }

    /// åšå‡ºæ‰©ç¼©å®¹å†³ç­–
    pub async fn make_scaling_decision(&self, current_instances: u32) -> ClusterResult<ScalingDecision> {
        let metrics = self.current_metrics.read().await.clone();
        let mut decision_metrics = HashMap::new();

        // æ”¶é›†å†³ç­–ä¾æ®çš„æŒ‡æ ‡
        decision_metrics.insert("cpu_usage".to_string(), metrics.cpu_usage);
        decision_metrics.insert("memory_usage".to_string(), metrics.memory_usage);
        decision_metrics.insert("avg_response_time".to_string(), metrics.avg_response_time);
        decision_metrics.insert("error_rate".to_string(), metrics.error_rate);
        decision_metrics.insert("throughput".to_string(), metrics.throughput);

        let action = match self.config.strategy {
            crate::config::ScalingStrategy::CpuBased => self.decide_cpu_based(&metrics, current_instances).await,
            crate::config::ScalingStrategy::MemoryBased => self.decide_memory_based(&metrics, current_instances).await,
            crate::config::ScalingStrategy::ResponseTimeBased => self.decide_response_time_based(&metrics, current_instances).await,
            crate::config::ScalingStrategy::QueueBased => self.decide_queue_based(&metrics, current_instances).await,
            crate::config::ScalingStrategy::Hybrid => self.decide_hybrid(&metrics, current_instances).await,
            crate::config::ScalingStrategy::CustomMetrics => self.decide_custom_metrics(&metrics, current_instances).await,
        };

        // è®¡ç®—ç½®ä¿¡åº¦
        let confidence = self.calculate_confidence(&metrics, &action).await;

        Ok(ScalingDecision {
            timestamp: Utc::now(),
            current_instances,
            action,
            metrics: decision_metrics,
            confidence,
        })
    }

    /// æ‰§è¡Œæ‰©ç¼©å®¹åŠ¨ä½œ
    pub async fn execute_scaling_action(&self, decision: &ScalingDecision) -> ClusterResult<bool> {
        // æ£€æŸ¥å†·å´æ—¶é—´
        if !self.check_cooldown().await? {
            debug!("â° æ‰©ç¼©å®¹å†·å´æ—¶é—´æœªåˆ°ï¼Œè·³è¿‡æ‰§è¡Œ");
            return Ok(false);
        }

        // æ£€æŸ¥ç½®ä¿¡åº¦
        if decision.confidence < self.config.min_confidence {
            debug!("ğŸ¤” æ‰©ç¼©å®¹å†³ç­–ç½®ä¿¡åº¦ä¸è¶³: {:.2}", decision.confidence);
            return Ok(false);
        }

        let before_instances = decision.current_instances;
        let mut success = false;
        let mut error_message = None;

        match &decision.action {
            ScalingAction::ScaleUp { target_instances, reason } => {
                info!("ğŸ“ˆ æ‰§è¡Œæ‰©å®¹: {} -> {}, åŸå› : {}", before_instances, target_instances, reason);
                match self.scale_up(*target_instances - before_instances).await {
                    Ok(_) => success = true,
                    Err(e) => error_message = Some(e.to_string()),
                }
            }
            ScalingAction::ScaleDown { target_instances, reason } => {
                info!("ğŸ“‰ æ‰§è¡Œç¼©å®¹: {} -> {}, åŸå› : {}", before_instances, target_instances, reason);
                match self.scale_down(before_instances - *target_instances).await {
                    Ok(_) => success = true,
                    Err(e) => error_message = Some(e.to_string()),
                }
            }
            ScalingAction::NoAction => {
                debug!("âš–ï¸ æ— éœ€æ‰©ç¼©å®¹æ“ä½œ");
                return Ok(false);
            }
        }

        // è®°å½•æ‰©ç¼©å®¹å†å²
        let history = ScalingHistory {
            timestamp: Utc::now(),
            action: decision.action.clone(),
            before_instances,
            after_instances: match &decision.action {
                ScalingAction::ScaleUp { target_instances, .. } => *target_instances,
                ScalingAction::ScaleDown { target_instances, .. } => *target_instances,
                ScalingAction::NoAction => before_instances,
            },
            success,
            error_message,
        };

        {
            let mut scaling_history = self.scaling_history.write().await;
            scaling_history.push(history);

            // é™åˆ¶å†å²è®°å½•æ•°é‡
            if scaling_history.len() > self.config.max_history_entries {
                scaling_history.remove(0);
            }
        }

        // æ›´æ–°æœ€åæ‰©ç¼©å®¹æ—¶é—´
        if success {
            let mut last_scaling_time = self.last_scaling_time.write().await;
            *last_scaling_time = Some(Utc::now());
        }

        Ok(success)
    }

    /// è·å–æ‰©ç¼©å®¹å†å²
    pub async fn get_scaling_history(&self) -> Vec<ScalingHistory> {
        self.scaling_history.read().await.clone()
    }

    /// è·å–å½“å‰æ€§èƒ½æŒ‡æ ‡
    pub async fn get_current_metrics(&self) -> PerformanceMetrics {
        self.current_metrics.read().await.clone()
    }

    // ç§æœ‰æ–¹æ³•

    async fn start_metrics_collection(&self) -> ClusterResult<()> {
        let _current_metrics = self.current_metrics.clone();
        let running = self.running.clone();
        let collection_interval = self.config.metrics_collection_interval;

        tokio::spawn(async move {
            let mut interval = tokio::time::interval(collection_interval);

            loop {
                interval.tick().await;

                // æ£€æŸ¥æ˜¯å¦è¿˜åœ¨è¿è¡Œ
                {
                    let running = running.read().await;
                    if !*running {
                        break;
                    }
                }

                // TODO: å®é™…çš„æŒ‡æ ‡æ”¶é›†é€»è¾‘
                // è¿™é‡Œåº”è¯¥ä»ç³»ç»Ÿç›‘æ§ã€Prometheusç­‰è·å–çœŸå®æŒ‡æ ‡
                debug!("ğŸ“Š æ”¶é›†æ€§èƒ½æŒ‡æ ‡");
            }
        });

        Ok(())
    }

    async fn start_scaling_decision(&self) -> ClusterResult<()> {
        let running = self.running.clone();
        let decision_interval = self.config.decision_interval;

        tokio::spawn(async move {
            let mut interval = tokio::time::interval(decision_interval);

            loop {
                interval.tick().await;

                // æ£€æŸ¥æ˜¯å¦è¿˜åœ¨è¿è¡Œ
                {
                    let running = running.read().await;
                    if !*running {
                        break;
                    }
                }

                // TODO: å®é™…çš„æ‰©ç¼©å®¹å†³ç­–é€»è¾‘
                // è¿™é‡Œåº”è¯¥è°ƒç”¨make_scaling_decisionå’Œexecute_scaling_action
                debug!("ğŸ¤– æ‰§è¡Œæ‰©ç¼©å®¹å†³ç­–");
            }
        });

        Ok(())
    }

    async fn decide_cpu_based(&self, metrics: &PerformanceMetrics, current_instances: u32) -> ScalingAction {
        if metrics.cpu_usage > self.config.scale_up_threshold {
            let target = (current_instances + self.config.scale_up_step).min(self.config.max_instances);
            ScalingAction::ScaleUp {
                target_instances: target,
                reason: format!("CPUä½¿ç”¨ç‡è¿‡é«˜: {:.1}%", metrics.cpu_usage * 100.0),
            }
        } else if metrics.cpu_usage < self.config.scale_down_threshold && current_instances > self.config.min_instances {
            let target = (current_instances.saturating_sub(self.config.scale_down_step)).max(self.config.min_instances);
            ScalingAction::ScaleDown {
                target_instances: target,
                reason: format!("CPUä½¿ç”¨ç‡è¿‡ä½: {:.1}%", metrics.cpu_usage * 100.0),
            }
        } else {
            ScalingAction::NoAction
        }
    }

    async fn decide_memory_based(&self, metrics: &PerformanceMetrics, current_instances: u32) -> ScalingAction {
        if metrics.memory_usage > self.config.scale_up_threshold {
            let target = (current_instances + self.config.scale_up_step).min(self.config.max_instances);
            ScalingAction::ScaleUp {
                target_instances: target,
                reason: format!("å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {:.1}%", metrics.memory_usage * 100.0),
            }
        } else if metrics.memory_usage < self.config.scale_down_threshold && current_instances > self.config.min_instances {
            let target = (current_instances.saturating_sub(self.config.scale_down_step)).max(self.config.min_instances);
            ScalingAction::ScaleDown {
                target_instances: target,
                reason: format!("å†…å­˜ä½¿ç”¨ç‡è¿‡ä½: {:.1}%", metrics.memory_usage * 100.0),
            }
        } else {
            ScalingAction::NoAction
        }
    }

    async fn decide_response_time_based(&self, metrics: &PerformanceMetrics, current_instances: u32) -> ScalingAction {
        let threshold_ms = self.config.scale_up_threshold * 1000.0; // è½¬æ¢ä¸ºæ¯«ç§’
        
        if metrics.avg_response_time > threshold_ms {
            let target = (current_instances + self.config.scale_up_step).min(self.config.max_instances);
            ScalingAction::ScaleUp {
                target_instances: target,
                reason: format!("å“åº”æ—¶é—´è¿‡é•¿: {:.1}ms", metrics.avg_response_time),
            }
        } else if metrics.avg_response_time < threshold_ms * self.config.scale_down_threshold && current_instances > self.config.min_instances {
            let target = (current_instances.saturating_sub(self.config.scale_down_step)).max(self.config.min_instances);
            ScalingAction::ScaleDown {
                target_instances: target,
                reason: format!("å“åº”æ—¶é—´è‰¯å¥½: {:.1}ms", metrics.avg_response_time),
            }
        } else {
            ScalingAction::NoAction
        }
    }

    async fn decide_queue_based(&self, metrics: &PerformanceMetrics, current_instances: u32) -> ScalingAction {
        let threshold = (self.config.scale_up_threshold * 100.0) as u32; // é˜Ÿåˆ—é•¿åº¦é˜ˆå€¼
        
        if metrics.queue_length > threshold {
            let target = (current_instances + self.config.scale_up_step).min(self.config.max_instances);
            ScalingAction::ScaleUp {
                target_instances: target,
                reason: format!("æ¶ˆæ¯é˜Ÿåˆ—è¿‡é•¿: {}", metrics.queue_length),
            }
        } else if metrics.queue_length < (threshold as f64 * self.config.scale_down_threshold) as u32 && current_instances > self.config.min_instances {
            let target = (current_instances.saturating_sub(self.config.scale_down_step)).max(self.config.min_instances);
            ScalingAction::ScaleDown {
                target_instances: target,
                reason: format!("æ¶ˆæ¯é˜Ÿåˆ—è¾ƒçŸ­: {}", metrics.queue_length),
            }
        } else {
            ScalingAction::NoAction
        }
    }

    async fn decide_hybrid(&self, metrics: &PerformanceMetrics, current_instances: u32) -> ScalingAction {
        // æ··åˆç­–ç•¥ï¼šç»¼åˆè€ƒè™‘å¤šä¸ªæŒ‡æ ‡
        let mut scale_up_score = 0.0;
        let mut scale_down_score = 0.0;

        // CPUæŒ‡æ ‡æƒé‡
        if metrics.cpu_usage > self.config.scale_up_threshold {
            scale_up_score += 0.3;
        } else if metrics.cpu_usage < self.config.scale_down_threshold {
            scale_down_score += 0.3;
        }

        // å†…å­˜æŒ‡æ ‡æƒé‡
        if metrics.memory_usage > self.config.scale_up_threshold {
            scale_up_score += 0.2;
        } else if metrics.memory_usage < self.config.scale_down_threshold {
            scale_down_score += 0.2;
        }

        // å“åº”æ—¶é—´æŒ‡æ ‡æƒé‡
        let response_threshold = self.config.scale_up_threshold * 1000.0;
        if metrics.avg_response_time > response_threshold {
            scale_up_score += 0.3;
        } else if metrics.avg_response_time < response_threshold * self.config.scale_down_threshold {
            scale_down_score += 0.3;
        }

        // é”™è¯¯ç‡æŒ‡æ ‡æƒé‡
        if metrics.error_rate > 0.05 { // 5%é”™è¯¯ç‡é˜ˆå€¼
            scale_up_score += 0.2;
        } else if metrics.error_rate < 0.01 { // 1%é”™è¯¯ç‡é˜ˆå€¼
            scale_down_score += 0.2;
        }

        if scale_up_score > 0.5 && current_instances < self.config.max_instances {
            let target = (current_instances + self.config.scale_up_step).min(self.config.max_instances);
            ScalingAction::ScaleUp {
                target_instances: target,
                reason: format!("æ··åˆæŒ‡æ ‡å»ºè®®æ‰©å®¹ (è¯„åˆ†: {:.2})", scale_up_score),
            }
        } else if scale_down_score > 0.5 && current_instances > self.config.min_instances {
            let target = (current_instances.saturating_sub(self.config.scale_down_step)).max(self.config.min_instances);
            ScalingAction::ScaleDown {
                target_instances: target,
                reason: format!("æ··åˆæŒ‡æ ‡å»ºè®®ç¼©å®¹ (è¯„åˆ†: {:.2})", scale_down_score),
            }
        } else {
            ScalingAction::NoAction
        }
    }

    async fn decide_custom_metrics(&self, _metrics: &PerformanceMetrics, _current_instances: u32) -> ScalingAction {
        // åŸºäºè‡ªå®šä¹‰æŒ‡æ ‡çš„å†³ç­–
        // TODO: å®ç°è‡ªå®šä¹‰æŒ‡æ ‡é€»è¾‘
        ScalingAction::NoAction
    }

    async fn calculate_confidence(&self, metrics: &PerformanceMetrics, action: &ScalingAction) -> f64 {
        // åŸºäºæŒ‡æ ‡çš„ç¨³å®šæ€§å’Œå†å²æˆåŠŸç‡è®¡ç®—ç½®ä¿¡åº¦
        let mut confidence: f64 = 0.5; // åŸºç¡€ç½®ä¿¡åº¦

        // æ ¹æ®æŒ‡æ ‡çš„æç«¯ç¨‹åº¦è°ƒæ•´ç½®ä¿¡åº¦
        match action {
            ScalingAction::ScaleUp { .. } => {
                if metrics.cpu_usage > 0.8 || metrics.memory_usage > 0.8 || metrics.avg_response_time > 2000.0 {
                    confidence += 0.3;
                }
                if metrics.error_rate > 0.1 {
                    confidence += 0.2;
                }
            }
            ScalingAction::ScaleDown { .. } => {
                if metrics.cpu_usage < 0.2 && metrics.memory_usage < 0.2 && metrics.avg_response_time < 100.0 {
                    confidence += 0.3;
                }
                if metrics.error_rate < 0.01 {
                    confidence += 0.2;
                }
            }
            ScalingAction::NoAction => {
                confidence = 1.0; // ä¸æ“ä½œæ€»æ˜¯å®‰å…¨çš„
            }
        }

        confidence.min(1.0)
    }

    async fn check_cooldown(&self) -> ClusterResult<bool> {
        let last_scaling_time = self.last_scaling_time.read().await;
        
        if let Some(last_time) = *last_scaling_time {
            let elapsed = Utc::now() - last_time;
            let cooldown_duration = Duration::seconds(self.config.cooldown_period.as_secs() as i64);
            Ok(elapsed >= cooldown_duration)
        } else {
            Ok(true) // é¦–æ¬¡æ‰©ç¼©å®¹
        }
    }

    async fn scale_up(&self, instances: u32) -> ClusterResult<()> {
        // TODO: å®é™…çš„æ‰©å®¹é€»è¾‘
        // è¿™é‡Œåº”è¯¥è°ƒç”¨å®¹å™¨ç¼–æ’ç³»ç»Ÿï¼ˆå¦‚Kubernetesï¼‰æˆ–äº‘æœåŠ¡API
        info!("ğŸš€ æ‰©å®¹ {} ä¸ªå®ä¾‹", instances);
        Ok(())
    }

    async fn scale_down(&self, instances: u32) -> ClusterResult<()> {
        // TODO: å®é™…çš„ç¼©å®¹é€»è¾‘
        // è¿™é‡Œåº”è¯¥ä¼˜é›…åœ°åœæ­¢å®ä¾‹å¹¶ä»è´Ÿè½½å‡è¡¡å™¨ä¸­ç§»é™¤
        info!("ğŸ”½ ç¼©å®¹ {} ä¸ªå®ä¾‹", instances);
        Ok(())
    }
}
